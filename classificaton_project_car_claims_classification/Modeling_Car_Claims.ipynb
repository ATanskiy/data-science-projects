{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddb5a58d",
   "metadata": {},
   "source": [
    "# Welcome to this lovely notebook. This is the extention of the notebook EDA with data preprocessing and modeling parts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362a0daa",
   "metadata": {},
   "source": [
    "## In this notebook we are going to implement the following:\n",
    "\n",
    "1. Runnig the base version of the 5 chosen models (Logistic regression, Decision Trees, Random Forest, XGBoost, CatBoost)\n",
    "2. After running the base version of the model, we'll create a pipe line with gridsearch and various parameters for getting the best parameters and score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fd4b92",
   "metadata": {},
   "source": [
    "## Importing all required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5e9439df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all the required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the option to display all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score,\\\n",
    "classification_report, precision_recall_curve, auc, make_scorer, fbeta_score\n",
    "\n",
    "# Encoding\n",
    "from sklearn.preprocessing import OneHotEncoder, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# SMOTE Oversampling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# RFECV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Machine Learning - Preparation\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "# Machine Learning - Algorithm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffd77c1",
   "metadata": {},
   "source": [
    "## Let's get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a67e9293",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('fraud_vihecles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c3e1281",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\atans\\AppData\\Local\\Temp\\ipykernel_12240\\581277815.py:1: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:60% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>WeekOfMonth</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Make</th>\n",
       "      <th>AccidentArea</th>\n",
       "      <th>DayOfWeekClaimed</th>\n",
       "      <th>MonthClaimed</th>\n",
       "      <th>WeekOfMonthClaimed</th>\n",
       "      <th>Sex</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fault</th>\n",
       "      <th>PolicyType</th>\n",
       "      <th>VehicleCategory</th>\n",
       "      <th>VehiclePrice</th>\n",
       "      <th>FraudFound_P</th>\n",
       "      <th>PolicyNumber</th>\n",
       "      <th>RepNumber</th>\n",
       "      <th>Deductible</th>\n",
       "      <th>DriverRating</th>\n",
       "      <th>Days_Policy_Accident</th>\n",
       "      <th>Days_Policy_Claim</th>\n",
       "      <th>PastNumberOfClaims</th>\n",
       "      <th>AgeOfVehicle</th>\n",
       "      <th>AgeOfPolicyHolder</th>\n",
       "      <th>PoliceReportFiled</th>\n",
       "      <th>WitnessPresent</th>\n",
       "      <th>AgentType</th>\n",
       "      <th>NumberOfSuppliments</th>\n",
       "      <th>AddressChange_Claim</th>\n",
       "      <th>NumberOfCars</th>\n",
       "      <th>Year</th>\n",
       "      <th>BasePolicy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dec</td>\n",
       "      <td>5</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>Honda</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Jan</td>\n",
       "      <td>1</td>\n",
       "      <td>Female</td>\n",
       "      <td>Single</td>\n",
       "      <td>21</td>\n",
       "      <td>Policy Holder</td>\n",
       "      <td>Sport - Liability</td>\n",
       "      <td>Sport</td>\n",
       "      <td>more than 69000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>more than 30</td>\n",
       "      <td>more than 30</td>\n",
       "      <td>none</td>\n",
       "      <td>3 years</td>\n",
       "      <td>26 to 30</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>External</td>\n",
       "      <td>none</td>\n",
       "      <td>1 year</td>\n",
       "      <td>3 to 4</td>\n",
       "      <td>1994</td>\n",
       "      <td>Liability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jan</td>\n",
       "      <td>3</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>Honda</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Jan</td>\n",
       "      <td>4</td>\n",
       "      <td>Male</td>\n",
       "      <td>Single</td>\n",
       "      <td>34</td>\n",
       "      <td>Policy Holder</td>\n",
       "      <td>Sport - Collision</td>\n",
       "      <td>Sport</td>\n",
       "      <td>more than 69000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>400</td>\n",
       "      <td>4</td>\n",
       "      <td>more than 30</td>\n",
       "      <td>more than 30</td>\n",
       "      <td>none</td>\n",
       "      <td>6 years</td>\n",
       "      <td>31 to 35</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>External</td>\n",
       "      <td>none</td>\n",
       "      <td>no change</td>\n",
       "      <td>1 vehicle</td>\n",
       "      <td>1994</td>\n",
       "      <td>Collision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Oct</td>\n",
       "      <td>5</td>\n",
       "      <td>Friday</td>\n",
       "      <td>Honda</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>Nov</td>\n",
       "      <td>2</td>\n",
       "      <td>Male</td>\n",
       "      <td>Married</td>\n",
       "      <td>47</td>\n",
       "      <td>Policy Holder</td>\n",
       "      <td>Sport - Collision</td>\n",
       "      <td>Sport</td>\n",
       "      <td>more than 69000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>400</td>\n",
       "      <td>3</td>\n",
       "      <td>more than 30</td>\n",
       "      <td>more than 30</td>\n",
       "      <td>1</td>\n",
       "      <td>7 years</td>\n",
       "      <td>41 to 50</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>External</td>\n",
       "      <td>none</td>\n",
       "      <td>no change</td>\n",
       "      <td>1 vehicle</td>\n",
       "      <td>1994</td>\n",
       "      <td>Collision</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Month  WeekOfMonth  DayOfWeek   Make AccidentArea DayOfWeekClaimed  \\\n",
       "0   Dec            5  Wednesday  Honda        Urban          Tuesday   \n",
       "1   Jan            3  Wednesday  Honda        Urban           Monday   \n",
       "2   Oct            5     Friday  Honda        Urban         Thursday   \n",
       "\n",
       "  MonthClaimed  WeekOfMonthClaimed     Sex MaritalStatus  Age          Fault  \\\n",
       "0          Jan                   1  Female        Single   21  Policy Holder   \n",
       "1          Jan                   4    Male        Single   34  Policy Holder   \n",
       "2          Nov                   2    Male       Married   47  Policy Holder   \n",
       "\n",
       "          PolicyType VehicleCategory     VehiclePrice  FraudFound_P  \\\n",
       "0  Sport - Liability           Sport  more than 69000             0   \n",
       "1  Sport - Collision           Sport  more than 69000             0   \n",
       "2  Sport - Collision           Sport  more than 69000             0   \n",
       "\n",
       "   PolicyNumber  RepNumber  Deductible  DriverRating Days_Policy_Accident  \\\n",
       "0             1         12         300             1         more than 30   \n",
       "1             2         15         400             4         more than 30   \n",
       "2             3          7         400             3         more than 30   \n",
       "\n",
       "  Days_Policy_Claim PastNumberOfClaims AgeOfVehicle AgeOfPolicyHolder  \\\n",
       "0      more than 30               none      3 years          26 to 30   \n",
       "1      more than 30               none      6 years          31 to 35   \n",
       "2      more than 30                  1      7 years          41 to 50   \n",
       "\n",
       "  PoliceReportFiled WitnessPresent AgentType NumberOfSuppliments  \\\n",
       "0                No             No  External                none   \n",
       "1               Yes             No  External                none   \n",
       "2                No             No  External                none   \n",
       "\n",
       "  AddressChange_Claim NumberOfCars  Year BasePolicy  \n",
       "0              1 year       3 to 4  1994  Liability  \n",
       "1           no change    1 vehicle  1994  Collision  \n",
       "2           no change    1 vehicle  1994  Collision  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(HTML(\"<style>.container { width:60% !important; }</style>\"))\n",
    "\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8804eade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgeOfPolicyHolder\n",
       "16 to 17    320\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['Age']==0]['AgeOfPolicyHolder'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9cab5c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              PolicyNumber  FraudFound_P\n",
      "PolicyNumber      1.000000     -0.020345\n",
      "FraudFound_P     -0.020345      1.000000\n"
     ]
    }
   ],
   "source": [
    "# Check the correlation\n",
    "print(data[['PolicyNumber', 'FraudFound_P']].corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722a7b0e",
   "metadata": {},
   "source": [
    "## 1.Let's split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a1354d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set X and y\n",
    "X = data.drop(columns=['FraudFound_P'])\n",
    "y = data['FraudFound_P']\n",
    "\n",
    "# Split the data with stratification on the target column\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d63555",
   "metadata": {},
   "source": [
    "## 2. Dropping the useless columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9ae39017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the custom function to drop specified columns\n",
    "def drop_columns(X, columns_to_drop):\n",
    "    return X.drop(columns=columns_to_drop)\n",
    "\n",
    "# List of columns to drop\n",
    "columns_to_drop = ['PolicyNumber'] #['WeekOfMonth', 'DayOfWeek', 'RepNumber', , 'Age']\n",
    "\n",
    "# Create the transformer\n",
    "drop_columns_transformer = FunctionTransformer(drop_columns, kw_args={'columns_to_drop': columns_to_drop})\n",
    "\n",
    "# Apply the transformer\n",
    "X_train_removed_columns = drop_columns_transformer.transform(X_train)\n",
    "X_test_removed_columns = drop_columns_transformer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3053d9d0",
   "metadata": {},
   "source": [
    "## 3. Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb796803",
   "metadata": {},
   "source": [
    "### Hot encoding the train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bd7e461f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the OneHotEncoder\n",
    "encoder = OneHotEncoder()\n",
    "\n",
    "# Fit and transform the data (train and test)\n",
    "X_train_cat_transformed = encoder.fit_transform(X_train_removed_columns)\n",
    "X_test_cat_transformed = encoder.transform(X_test_removed_columns)\n",
    "\n",
    "# Convert the result to a DataFrame for better readability\n",
    "X_train_encoded = pd.DataFrame(X_train_cat_transformed.toarray(), columns=encoder.get_feature_names_out(X_train_removed_columns.columns))\n",
    "X_test_encoded = pd.DataFrame(X_test_cat_transformed.toarray(), columns=encoder.get_feature_names_out(X_test_removed_columns.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dbcfc41f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11565, 243), (3855, 243))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_encoded.shape, X_test_encoded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e1da72",
   "metadata": {},
   "source": [
    "### The data is ready. Let's start modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503870ee",
   "metadata": {},
   "source": [
    "## 4. Modeling with Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c54435",
   "metadata": {},
   "source": [
    "#### 4.1 Building a benchmark model to take a look what we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "1b9cb09f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-47 {color: black;}#sk-container-id-47 pre{padding: 0;}#sk-container-id-47 div.sk-toggleable {background-color: white;}#sk-container-id-47 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-47 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-47 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-47 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-47 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-47 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-47 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-47 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-47 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-47 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-47 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-47 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-47 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-47 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-47 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-47 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-47 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-47 div.sk-item {position: relative;z-index: 1;}#sk-container-id-47 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-47 div.sk-item::before, #sk-container-id-47 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-47 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-47 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-47 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-47 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-47 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-47 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-47 div.sk-label-container {text-align: center;}#sk-container-id-47 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-47 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-47\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=10000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-47\" type=\"checkbox\" checked><label for=\"sk-estimator-id-47\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=10000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=10000)"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first let's instantiate the model\n",
    "lr = LogisticRegression(max_iter=10000)\n",
    "\n",
    "# Let's fit\n",
    "lr.fit(X_train_encoded, y_train)\n",
    "#lr.fit(X_train_label_encoded, y_train) Label encoding didn't help improving the Logistic regression at all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7d309c",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "81d686ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0   1\n",
      "0  10851  22\n",
      "1    672  20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97     10873\n",
      "           1       0.48      0.03      0.05       692\n",
      "\n",
      "    accuracy                           0.94     11565\n",
      "   macro avg       0.71      0.51      0.51     11565\n",
      "weighted avg       0.91      0.94      0.91     11565\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Running on train data\n",
    "cm = confusion_matrix(y_true=y_train,\n",
    "                      y_pred=lr.predict(X_train_encoded))\n",
    "print(pd.DataFrame(cm,\n",
    "             index=lr.classes_,\n",
    "             columns=lr.classes_))\n",
    "\n",
    "print(classification_report(y_train, lr.predict(X_train_encoded)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077db958",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "6299861c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0   1\n",
      "0  3614  10\n",
      "1   229   2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      3624\n",
      "           1       0.17      0.01      0.02       231\n",
      "\n",
      "    accuracy                           0.94      3855\n",
      "   macro avg       0.55      0.50      0.49      3855\n",
      "weighted avg       0.89      0.94      0.91      3855\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Running on test data\n",
    "cm = confusion_matrix(y_true=y_test,\n",
    "                      y_pred=lr.predict(X_test_encoded))\n",
    "print(pd.DataFrame(cm,\n",
    "             index=lr.classes_,\n",
    "             columns=lr.classes_))\n",
    "print(classification_report(y_test, lr.predict(X_test_encoded)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba4cc58",
   "metadata": {},
   "source": [
    "#### 4.2 Pipeline with gridsearch and finding the best hyperparameters and learning the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "0f0e4b8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE config: {'smote': None, 'under_sampler': None}, CV: 3\n",
      "Best parameters: {'classifier__C': 1, 'classifier__class_weight': 'balanced', 'classifier__penalty': 'l2', 'classifier__solver': 'liblinear'}\n",
      "Best cross-validation score: 0.23081909418361754\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.65      0.79      3624\n",
      "           1       0.13      0.81      0.22       231\n",
      "\n",
      "    accuracy                           0.66      3855\n",
      "   macro avg       0.56      0.73      0.51      3855\n",
      "weighted avg       0.93      0.66      0.75      3855\n",
      "\n",
      "      0     1\n",
      "0  2371  1253\n",
      "1    43   188\n",
      "\n",
      "Detailed cross-validation scores:\n",
      "    mean_test_score  std_test_score\n",
      "0          0.000000        0.000000\n",
      "1          0.000000        0.000000\n",
      "2          0.000000        0.000000\n",
      "3          0.000000        0.000000\n",
      "4          0.216220        0.006385\n",
      "5          0.199877        0.019647\n",
      "6          0.226220        0.007160\n",
      "7          0.183777        0.017214\n",
      "8          0.000000        0.000000\n",
      "9          0.000000        0.000000\n",
      "10         0.000000        0.000000\n",
      "11         0.000000        0.000000\n",
      "12         0.226057        0.006185\n",
      "13         0.192176        0.025662\n",
      "14         0.228906        0.000492\n",
      "15         0.223167        0.010438\n",
      "16         0.013788        0.003732\n",
      "17         0.013788        0.003732\n",
      "18         0.019143        0.003649\n",
      "19         0.019143        0.003649\n",
      "20         0.229557        0.001028\n",
      "21         0.197238        0.006651\n",
      "22         0.230819        0.002063\n",
      "23         0.106024        0.082758\n",
      "24         0.032192        0.010929\n",
      "25         0.032192        0.010929\n",
      "26         0.032192        0.010929\n",
      "27         0.032192        0.010929\n",
      "28         0.226998        0.001681\n",
      "29         0.169008        0.058982\n",
      "30         0.227646        0.001774\n",
      "31         0.174378        0.051113\n",
      "32         0.032146        0.010995\n",
      "33         0.032146        0.010995\n",
      "34         0.032146        0.010995\n",
      "35         0.032146        0.010995\n",
      "36         0.226825        0.001233\n",
      "37         0.201902        0.004996\n",
      "38         0.226926        0.001216\n",
      "39         0.206764        0.014753\n",
      "\n",
      "SMOTE config: {'smote': None, 'under_sampler': None}, CV: 4\n",
      "Best parameters: {'classifier__C': 0.1, 'classifier__class_weight': 'balanced', 'classifier__penalty': 'l2', 'classifier__solver': 'liblinear'}\n",
      "Best cross-validation score: 0.23577038610800236\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.65      0.78      3624\n",
      "           1       0.13      0.83      0.23       231\n",
      "\n",
      "    accuracy                           0.66      3855\n",
      "   macro avg       0.56      0.74      0.50      3855\n",
      "weighted avg       0.93      0.66      0.75      3855\n",
      "\n",
      "      0     1\n",
      "0  2342  1282\n",
      "1    39   192\n",
      "\n",
      "Detailed cross-validation scores:\n",
      "    mean_test_score  std_test_score\n",
      "0          0.000000        0.000000\n",
      "1          0.000000        0.000000\n",
      "2          0.000000        0.000000\n",
      "3          0.000000        0.000000\n",
      "4          0.216319        0.010154\n",
      "5          0.199798        0.019737\n",
      "6          0.228954        0.012470\n",
      "7          0.170339        0.038344\n",
      "8          0.000000        0.000000\n",
      "9          0.000000        0.000000\n",
      "10         0.000000        0.000000\n",
      "11         0.000000        0.000000\n",
      "12         0.231900        0.011940\n",
      "13         0.185680        0.033698\n",
      "14         0.235770        0.010836\n",
      "15         0.208788        0.012056\n",
      "16         0.013828        0.011954\n",
      "17         0.013828        0.011954\n",
      "18         0.019142        0.014051\n",
      "19         0.019142        0.014051\n",
      "20         0.234173        0.011710\n",
      "21         0.213874        0.013258\n",
      "22         0.234979        0.010111\n",
      "23         0.209075        0.018272\n",
      "24         0.029733        0.013708\n",
      "25         0.029733        0.013708\n",
      "26         0.029763        0.013691\n",
      "27         0.029763        0.013691\n",
      "28         0.234723        0.013426\n",
      "29         0.164458        0.042732\n",
      "30         0.234546        0.012920\n",
      "31         0.192461        0.033450\n",
      "32         0.029632        0.013602\n",
      "33         0.029662        0.013585\n",
      "34         0.029662        0.013585\n",
      "35         0.029662        0.013585\n",
      "36         0.234252        0.013583\n",
      "37         0.223509        0.013567\n",
      "38         0.234402        0.013587\n",
      "39         0.137638        0.067399\n",
      "\n",
      "SMOTE config: {'smote': None, 'under_sampler': None}, CV: 5\n",
      "Best parameters: {'classifier__C': 0.1, 'classifier__class_weight': 'balanced', 'classifier__penalty': 'l2', 'classifier__solver': 'liblinear'}\n",
      "Best cross-validation score: 0.2335029132938411\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.65      0.78      3624\n",
      "           1       0.13      0.83      0.23       231\n",
      "\n",
      "    accuracy                           0.66      3855\n",
      "   macro avg       0.56      0.74      0.50      3855\n",
      "weighted avg       0.93      0.66      0.75      3855\n",
      "\n",
      "      0     1\n",
      "0  2342  1282\n",
      "1    39   192\n",
      "\n",
      "Detailed cross-validation scores:\n",
      "    mean_test_score  std_test_score\n",
      "0          0.000000        0.000000\n",
      "1          0.000000        0.000000\n",
      "2          0.000000        0.000000\n",
      "3          0.000000        0.000000\n",
      "4          0.216354        0.010832\n",
      "5          0.150512        0.063607\n",
      "6          0.227177        0.011628\n",
      "7          0.178943        0.011822\n",
      "8          0.000000        0.000000\n",
      "9          0.000000        0.000000\n",
      "10         0.002778        0.005556\n",
      "11         0.002778        0.005556\n",
      "12         0.229472        0.009924\n",
      "13         0.214141        0.009961\n",
      "14         0.233503        0.010269\n",
      "15         0.208112        0.013141\n",
      "16         0.013700        0.014904\n",
      "17         0.013700        0.014904\n",
      "18         0.013662        0.014904\n",
      "19         0.013662        0.014904\n",
      "20         0.231938        0.010594\n",
      "21         0.213008        0.011078\n",
      "22         0.232019        0.011094\n",
      "23         0.210500        0.016849\n",
      "24         0.029622        0.017864\n",
      "25         0.029622        0.017864\n",
      "26         0.032288        0.018295\n",
      "27         0.032288        0.018295\n",
      "28         0.231961        0.013494\n",
      "29         0.196131        0.024933\n",
      "30         0.231919        0.013115\n",
      "31         0.193670        0.022248\n",
      "32         0.032288        0.018295\n",
      "33         0.032288        0.018295\n",
      "34         0.032288        0.018295\n",
      "35         0.032288        0.018295\n",
      "36         0.231172        0.013763\n",
      "37         0.205668        0.014899\n",
      "38         0.231269        0.013757\n",
      "39         0.207542        0.018329\n",
      "\n",
      "SMOTE config: {'smote': None, 'under_sampler': RandomUnderSampler(random_state=42, sampling_strategy=0.6)}, CV: 3\n",
      "Best parameters: {'classifier__C': 0.1, 'classifier__class_weight': None, 'classifier__penalty': 'l2', 'classifier__solver': 'liblinear'}\n",
      "Best cross-validation score: 0.23681917847454134\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.74      0.84      3624\n",
      "           1       0.14      0.65      0.23       231\n",
      "\n",
      "    accuracy                           0.73      3855\n",
      "   macro avg       0.55      0.69      0.53      3855\n",
      "weighted avg       0.92      0.73      0.80      3855\n",
      "\n",
      "      0    1\n",
      "0  2681  943\n",
      "1    82  149\n",
      "\n",
      "Detailed cross-validation scores:\n",
      "    mean_test_score  std_test_score\n",
      "0          0.000000        0.000000\n",
      "1          0.000000        0.000000\n",
      "2          0.223230        0.016273\n",
      "3          0.219188        0.013336\n",
      "4          0.000000        0.000000\n",
      "5          0.037536        0.053083\n",
      "6          0.218487        0.005512\n",
      "7          0.218963        0.005694\n",
      "8          0.222802        0.004659\n",
      "9          0.224415        0.002453\n",
      "10         0.236819        0.006830\n",
      "11         0.236633        0.006787\n",
      "12         0.217178        0.007354\n",
      "13         0.217178        0.007354\n",
      "14         0.223932        0.005198\n",
      "15         0.223932        0.005198\n",
      "16         0.233316        0.003710\n",
      "17         0.232880        0.003866\n",
      "18         0.231372        0.004878\n",
      "19         0.231312        0.004886\n",
      "20         0.225605        0.004357\n",
      "21         0.225605        0.004357\n",
      "22         0.227994        0.001943\n",
      "23         0.227994        0.001943\n",
      "24         0.227656        0.005743\n",
      "25         0.227659        0.005613\n",
      "26         0.227630        0.006422\n",
      "27         0.227634        0.006295\n",
      "28         0.226973        0.002229\n",
      "29         0.226973        0.002229\n",
      "30         0.228527        0.002864\n",
      "31         0.228576        0.002921\n",
      "32         0.224052        0.004824\n",
      "33         0.225203        0.005278\n",
      "34         0.225560        0.005388\n",
      "35         0.225745        0.005262\n",
      "36         0.225344        0.004244\n",
      "37         0.225662        0.004577\n",
      "38         0.225590        0.003883\n",
      "39         0.226100        0.003788\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE config: {'smote': None, 'under_sampler': RandomUnderSampler(random_state=42, sampling_strategy=0.6)}, CV: 4\n",
      "Best parameters: {'classifier__C': 1, 'classifier__class_weight': None, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "Best cross-validation score: 0.2338047837941732\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.73      0.83      3624\n",
      "           1       0.13      0.65      0.22       231\n",
      "\n",
      "    accuracy                           0.73      3855\n",
      "   macro avg       0.55      0.69      0.53      3855\n",
      "weighted avg       0.92      0.73      0.80      3855\n",
      "\n",
      "      0    1\n",
      "0  2652  972\n",
      "1    82  149\n",
      "\n",
      "Detailed cross-validation scores:\n",
      "    mean_test_score  std_test_score\n",
      "0          0.000000        0.000000\n",
      "1          0.000000        0.000000\n",
      "2          0.220365        0.009707\n",
      "3          0.220672        0.014180\n",
      "4          0.049902        0.086433\n",
      "5          0.156619        0.001737\n",
      "6          0.221602        0.011294\n",
      "7          0.221450        0.011629\n",
      "8          0.226442        0.016984\n",
      "9          0.226442        0.016984\n",
      "10         0.230088        0.011004\n",
      "11         0.230088        0.011004\n",
      "12         0.217235        0.010791\n",
      "13         0.217235        0.010791\n",
      "14         0.227341        0.009863\n",
      "15         0.227632        0.010087\n",
      "16         0.233805        0.006433\n",
      "17         0.233248        0.006062\n",
      "18         0.226284        0.004416\n",
      "19         0.226284        0.004416\n",
      "20         0.231791        0.007025\n",
      "21         0.231784        0.006987\n",
      "22         0.232722        0.007509\n",
      "23         0.232682        0.007571\n",
      "24         0.228497        0.005110\n",
      "25         0.228439        0.005062\n",
      "26         0.228549        0.005479\n",
      "27         0.228549        0.005479\n",
      "28         0.228043        0.006829\n",
      "29         0.228140        0.006877\n",
      "30         0.227407        0.005845\n",
      "31         0.227407        0.005845\n",
      "32         0.227148        0.005564\n",
      "33         0.226918        0.006172\n",
      "34         0.226885        0.006584\n",
      "35         0.226885        0.006584\n",
      "36         0.226192        0.007706\n",
      "37         0.226363        0.007599\n",
      "38         0.226514        0.007653\n",
      "39         0.226641        0.007537\n",
      "\n",
      "SMOTE config: {'smote': None, 'under_sampler': RandomUnderSampler(random_state=42, sampling_strategy=0.6)}, CV: 5\n",
      "Best parameters: {'classifier__C': 1, 'classifier__class_weight': None, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "Best cross-validation score: 0.24637694066072915\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.73      0.83      3624\n",
      "           1       0.13      0.65      0.22       231\n",
      "\n",
      "    accuracy                           0.73      3855\n",
      "   macro avg       0.55      0.69      0.53      3855\n",
      "weighted avg       0.92      0.73      0.80      3855\n",
      "\n",
      "      0    1\n",
      "0  2652  972\n",
      "1    82  149\n",
      "\n",
      "Detailed cross-validation scores:\n",
      "    mean_test_score  std_test_score\n",
      "0          0.000000        0.000000\n",
      "1          0.000000        0.000000\n",
      "2          0.238965        0.019981\n",
      "3          0.235557        0.021809\n",
      "4          0.038984        0.077969\n",
      "5          0.156622        0.000766\n",
      "6          0.221283        0.013287\n",
      "7          0.221646        0.013515\n",
      "8          0.240027        0.020080\n",
      "9          0.238605        0.019212\n",
      "10         0.243452        0.018250\n",
      "11         0.243516        0.018214\n",
      "12         0.217174        0.011200\n",
      "13         0.217211        0.011220\n",
      "14         0.227451        0.013103\n",
      "15         0.227452        0.013087\n",
      "16         0.246377        0.016779\n",
      "17         0.246302        0.016671\n",
      "18         0.241464        0.013291\n",
      "19         0.241464        0.013291\n",
      "20         0.230412        0.010327\n",
      "21         0.230412        0.010327\n",
      "22         0.234132        0.014613\n",
      "23         0.234132        0.014613\n",
      "24         0.240124        0.013951\n",
      "25         0.239867        0.013940\n",
      "26         0.240489        0.013662\n",
      "27         0.240489        0.013662\n",
      "28         0.232951        0.017412\n",
      "29         0.232951        0.017412\n",
      "30         0.231971        0.016809\n",
      "31         0.231917        0.016757\n",
      "32         0.241557        0.011656\n",
      "33         0.241834        0.011888\n",
      "34         0.241661        0.011391\n",
      "35         0.241734        0.011463\n",
      "36         0.231729        0.016282\n",
      "37         0.231504        0.016365\n",
      "38         0.231554        0.016364\n",
      "39         0.231174        0.016444\n",
      "\n",
      "SMOTE config: {'smote': None, 'under_sampler': RandomUnderSampler(random_state=42, sampling_strategy=0.5)}, CV: 3\n",
      "Best parameters: {'classifier__C': 0.1, 'classifier__class_weight': None, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "Best cross-validation score: 0.23806638332321392\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.80      0.88      3624\n",
      "           1       0.15      0.54      0.23       231\n",
      "\n",
      "    accuracy                           0.79      3855\n",
      "   macro avg       0.56      0.67      0.56      3855\n",
      "weighted avg       0.92      0.79      0.84      3855\n",
      "\n",
      "      0    1\n",
      "0  2915  709\n",
      "1   106  125\n",
      "\n",
      "Detailed cross-validation scores:\n",
      "    mean_test_score  std_test_score\n",
      "0          0.000000        0.000000\n",
      "1          0.000000        0.000000\n",
      "2          0.171260        0.021507\n",
      "3          0.172436        0.030034\n",
      "4          0.000000        0.000000\n",
      "5          0.104163        0.073655\n",
      "6          0.220135        0.005785\n",
      "7          0.219856        0.006178\n",
      "8          0.237287        0.008630\n",
      "9          0.238066        0.008327\n",
      "10         0.230881        0.006037\n",
      "11         0.230120        0.006931\n",
      "12         0.217412        0.007367\n",
      "13         0.217669        0.007439\n",
      "14         0.227639        0.006672\n",
      "15         0.227303        0.007113\n",
      "16         0.232107        0.013285\n",
      "17         0.232038        0.013253\n",
      "18         0.229661        0.011007\n",
      "19         0.229591        0.011006\n",
      "20         0.229646        0.002398\n",
      "21         0.229646        0.002398\n",
      "22         0.229900        0.006545\n",
      "23         0.229900        0.006545\n",
      "24         0.227104        0.009056\n",
      "25         0.227058        0.008826\n",
      "26         0.228007        0.008041\n",
      "27         0.228080        0.007939\n",
      "28         0.229022        0.007276\n",
      "29         0.229121        0.007280\n",
      "30         0.228982        0.006770\n",
      "31         0.228982        0.006770\n",
      "32         0.225852        0.006082\n",
      "33         0.226018        0.006263\n",
      "34         0.226889        0.006087\n",
      "35         0.226822        0.006080\n",
      "36         0.226345        0.006516\n",
      "37         0.226741        0.007328\n",
      "38         0.226523        0.006927\n",
      "39         0.226935        0.007391\n",
      "\n",
      "SMOTE config: {'smote': None, 'under_sampler': RandomUnderSampler(random_state=42, sampling_strategy=0.5)}, CV: 4\n",
      "Best parameters: {'classifier__C': 0.1, 'classifier__class_weight': None, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "Best cross-validation score: 0.23913102353450613\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.80      0.88      3624\n",
      "           1       0.15      0.54      0.23       231\n",
      "\n",
      "    accuracy                           0.79      3855\n",
      "   macro avg       0.56      0.67      0.56      3855\n",
      "weighted avg       0.92      0.79      0.84      3855\n",
      "\n",
      "      0    1\n",
      "0  2915  709\n",
      "1   106  125\n",
      "\n",
      "Detailed cross-validation scores:\n",
      "    mean_test_score  std_test_score\n",
      "0          0.000000        0.000000\n",
      "1          0.000000        0.000000\n",
      "2          0.191944        0.023084\n",
      "3          0.189023        0.023214\n",
      "4          0.216397        0.010207\n",
      "5          0.167542        0.018590\n",
      "6          0.221789        0.013120\n",
      "7          0.221955        0.013216\n",
      "8          0.239017        0.005409\n",
      "9          0.239131        0.005236\n",
      "10         0.229023        0.008035\n",
      "11         0.228849        0.007651\n",
      "12         0.217691        0.011402\n",
      "13         0.217691        0.011402\n",
      "14         0.225991        0.011461\n",
      "15         0.225991        0.011461\n",
      "16         0.233177        0.007219\n",
      "17         0.233245        0.007274\n",
      "18         0.227058        0.010758\n",
      "19         0.226971        0.010590\n",
      "20         0.232280        0.010433\n",
      "21         0.232280        0.010433\n",
      "22         0.233345        0.010988\n",
      "23         0.233296        0.010968\n",
      "24         0.225523        0.008288\n",
      "25         0.226068        0.007610\n",
      "26         0.224520        0.009365\n",
      "27         0.224463        0.009447\n",
      "28         0.231515        0.010036\n",
      "29         0.231565        0.010050\n",
      "30         0.232466        0.009080\n",
      "31         0.232416        0.009038\n",
      "32         0.226047        0.010487\n",
      "33         0.226108        0.010276\n",
      "34         0.226305        0.010238\n",
      "35         0.226305        0.010238\n",
      "36         0.231144        0.009233\n",
      "37         0.231409        0.008434\n",
      "38         0.231144        0.008347\n",
      "39         0.231144        0.008347\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE config: {'smote': None, 'under_sampler': RandomUnderSampler(random_state=42, sampling_strategy=0.5)}, CV: 5\n",
      "Best parameters: {'classifier__C': 1, 'classifier__class_weight': None, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "Best cross-validation score: 0.25042774059626377\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.78      0.86      3624\n",
      "           1       0.14      0.55      0.22       231\n",
      "\n",
      "    accuracy                           0.77      3855\n",
      "   macro avg       0.55      0.67      0.54      3855\n",
      "weighted avg       0.91      0.77      0.82      3855\n",
      "\n",
      "      0    1\n",
      "0  2829  795\n",
      "1   104  127\n",
      "\n",
      "Detailed cross-validation scores:\n",
      "    mean_test_score  std_test_score\n",
      "0          0.000000        0.000000\n",
      "1          0.000000        0.000000\n",
      "2          0.192766        0.028707\n",
      "3          0.187626        0.029277\n",
      "4          0.216354        0.010832\n",
      "5          0.189800        0.028730\n",
      "6          0.219826        0.013840\n",
      "7          0.220159        0.014092\n",
      "8          0.242453        0.017718\n",
      "9          0.241071        0.015735\n",
      "10         0.248316        0.015669\n",
      "11         0.248154        0.015706\n",
      "12         0.217251        0.011277\n",
      "13         0.217251        0.011277\n",
      "14         0.227937        0.013409\n",
      "15         0.227937        0.013409\n",
      "16         0.250428        0.018627\n",
      "17         0.250177        0.018539\n",
      "18         0.243877        0.011825\n",
      "19         0.244032        0.011830\n",
      "20         0.232627        0.011158\n",
      "21         0.232627        0.011158\n",
      "22         0.232636        0.015129\n",
      "23         0.232636        0.015129\n",
      "24         0.237331        0.011294\n",
      "25         0.237191        0.011248\n",
      "26         0.238576        0.011022\n",
      "27         0.238576        0.011022\n",
      "28         0.232464        0.017365\n",
      "29         0.232410        0.017309\n",
      "30         0.233268        0.016072\n",
      "31         0.233219        0.016072\n",
      "32         0.235603        0.010616\n",
      "33         0.235603        0.010728\n",
      "34         0.235749        0.010754\n",
      "35         0.235742        0.010692\n",
      "36         0.233222        0.015333\n",
      "37         0.233217        0.015276\n",
      "38         0.233365        0.015268\n",
      "39         0.233316        0.015268\n",
      "\n",
      "SMOTE config: {'smote': None, 'under_sampler': RandomUnderSampler(random_state=42, sampling_strategy=0.4)}, CV: 3\n",
      "Best parameters: {'classifier__C': 1, 'classifier__class_weight': 'balanced', 'classifier__penalty': 'l2', 'classifier__solver': 'liblinear'}\n",
      "Best cross-validation score: 0.23323927706149214\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.66      0.79      3624\n",
      "           1       0.13      0.79      0.22       231\n",
      "\n",
      "    accuracy                           0.66      3855\n",
      "   macro avg       0.55      0.72      0.50      3855\n",
      "weighted avg       0.93      0.66      0.75      3855\n",
      "\n",
      "      0     1\n",
      "0  2376  1248\n",
      "1    49   182\n",
      "\n",
      "Detailed cross-validation scores:\n",
      "    mean_test_score  std_test_score\n",
      "0          0.000000        0.000000\n",
      "1          0.000000        0.000000\n",
      "2          0.096775        0.022419\n",
      "3          0.085274        0.016115\n",
      "4          0.216220        0.006385\n",
      "5          0.173371        0.024220\n",
      "6          0.221876        0.008032\n",
      "7          0.221751        0.007829\n",
      "8          0.162272        0.036141\n",
      "9          0.155491        0.035618\n",
      "10         0.217447        0.018722\n",
      "11         0.217547        0.018863\n",
      "12         0.217841        0.007147\n",
      "13         0.217841        0.007147\n",
      "14         0.228790        0.005264\n",
      "15         0.228790        0.005264\n",
      "16         0.231121        0.014979\n",
      "17         0.230851        0.014980\n",
      "18         0.228077        0.010974\n",
      "19         0.227735        0.010659\n",
      "20         0.232404        0.005195\n",
      "21         0.232401        0.005086\n",
      "22         0.233239        0.005545\n",
      "23         0.233194        0.005588\n",
      "24         0.225105        0.008857\n",
      "25         0.224937        0.008971\n",
      "26         0.228595        0.007769\n",
      "27         0.228423        0.007884\n",
      "28         0.227949        0.004473\n",
      "29         0.227999        0.004413\n",
      "30         0.229148        0.004390\n",
      "31         0.229148        0.004390\n",
      "32         0.224146        0.007006\n",
      "33         0.224389        0.007109\n",
      "34         0.224482        0.006931\n",
      "35         0.224639        0.007139\n",
      "36         0.227074        0.004595\n",
      "37         0.227423        0.003946\n",
      "38         0.227611        0.004246\n",
      "39         0.227563        0.004181\n",
      "\n",
      "SMOTE config: {'smote': None, 'under_sampler': RandomUnderSampler(random_state=42, sampling_strategy=0.4)}, CV: 4\n",
      "Best parameters: {'classifier__C': 1, 'classifier__class_weight': None, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "Best cross-validation score: 0.2369795148883323\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.83      0.89      3624\n",
      "           1       0.15      0.45      0.22       231\n",
      "\n",
      "    accuracy                           0.81      3855\n",
      "   macro avg       0.55      0.64      0.56      3855\n",
      "weighted avg       0.91      0.81      0.85      3855\n",
      "\n",
      "      0    1\n",
      "0  3026  598\n",
      "1   128  103\n",
      "\n",
      "Detailed cross-validation scores:\n",
      "    mean_test_score  std_test_score\n",
      "0          0.000000        0.000000\n",
      "1          0.000000        0.000000\n",
      "2          0.116746        0.020464\n",
      "3          0.114270        0.022292\n",
      "4          0.216397        0.010207\n",
      "5          0.216397        0.010207\n",
      "6          0.221204        0.011948\n",
      "7          0.220949        0.012503\n",
      "8          0.232223        0.006198\n",
      "9          0.229238        0.003627\n",
      "10         0.225087        0.010973\n",
      "11         0.224692        0.010935\n",
      "12         0.217728        0.011403\n",
      "13         0.217728        0.011403\n",
      "14         0.227002        0.012496\n",
      "15         0.227002        0.012496\n",
      "16         0.236461        0.006603\n",
      "17         0.236980        0.006419\n",
      "18         0.229794        0.011965\n",
      "19         0.229736        0.012105\n",
      "20         0.231623        0.009290\n",
      "21         0.231623        0.009290\n",
      "22         0.233582        0.010356\n",
      "23         0.233582        0.010356\n",
      "24         0.222408        0.012602\n",
      "25         0.222997        0.012812\n",
      "26         0.225306        0.011712\n",
      "27         0.225306        0.011712\n",
      "28         0.231314        0.011501\n",
      "29         0.231456        0.011538\n",
      "30         0.230919        0.011526\n",
      "31         0.230919        0.011526\n",
      "32         0.223156        0.011616\n",
      "33         0.223531        0.011788\n",
      "34         0.223780        0.011808\n",
      "35         0.223647        0.012015\n",
      "36         0.230867        0.012211\n",
      "37         0.230856        0.012144\n",
      "38         0.230384        0.012661\n",
      "39         0.230371        0.012541\n",
      "\n",
      "SMOTE config: {'smote': None, 'under_sampler': RandomUnderSampler(random_state=42, sampling_strategy=0.4)}, CV: 5\n",
      "Best parameters: {'classifier__C': 1, 'classifier__class_weight': None, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "Best cross-validation score: 0.23979752061504578\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.83      0.89      3624\n",
      "           1       0.15      0.45      0.22       231\n",
      "\n",
      "    accuracy                           0.81      3855\n",
      "   macro avg       0.55      0.64      0.56      3855\n",
      "weighted avg       0.91      0.81      0.85      3855\n",
      "\n",
      "      0    1\n",
      "0  3026  598\n",
      "1   127  104\n",
      "\n",
      "Detailed cross-validation scores:\n",
      "    mean_test_score  std_test_score\n",
      "0          0.000000        0.000000\n",
      "1          0.000000        0.000000\n",
      "2          0.093792        0.027293\n",
      "3          0.090112        0.029497\n",
      "4          0.216354        0.010832\n",
      "5          0.216354        0.010832\n",
      "6          0.222155        0.013997\n",
      "7          0.221740        0.013710\n",
      "8          0.198830        0.016008\n",
      "9          0.199021        0.016137\n",
      "10         0.232921        0.015773\n",
      "11         0.233721        0.014693\n",
      "12         0.217268        0.012131\n",
      "13         0.217268        0.012131\n",
      "14         0.230570        0.010255\n",
      "15         0.230570        0.010255\n",
      "16         0.239798        0.020816\n",
      "17         0.239365        0.020991\n",
      "18         0.239626        0.021986\n",
      "19         0.239622        0.021943\n",
      "20         0.233728        0.009314\n",
      "21         0.233728        0.009314\n",
      "22         0.234666        0.012737\n",
      "23         0.234666        0.012737\n",
      "24         0.235315        0.022034\n",
      "25         0.235832        0.020795\n",
      "26         0.235237        0.018544\n",
      "27         0.235320        0.018532\n",
      "28         0.234505        0.015085\n",
      "29         0.234455        0.015088\n",
      "30         0.233169        0.015034\n",
      "31         0.233116        0.014987\n",
      "32         0.232754        0.020897\n",
      "33         0.232190        0.019983\n",
      "34         0.232542        0.020138\n",
      "35         0.232437        0.019958\n",
      "36         0.232809        0.014421\n",
      "37         0.233193        0.014804\n",
      "38         0.233629        0.014736\n",
      "39         0.233678        0.014731\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE config: {'smote': None, 'under_sampler': RandomUnderSampler(random_state=42, sampling_strategy=0.3)}, CV: 3\n",
      "Best parameters: {'classifier__C': 1, 'classifier__class_weight': 'balanced', 'classifier__penalty': 'l2', 'classifier__solver': 'liblinear'}\n",
      "Best cross-validation score: 0.2338186147796978\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.65      0.78      3624\n",
      "           1       0.13      0.81      0.22       231\n",
      "\n",
      "    accuracy                           0.66      3855\n",
      "   macro avg       0.56      0.73      0.50      3855\n",
      "weighted avg       0.93      0.66      0.75      3855\n",
      "\n",
      "      0     1\n",
      "0  2364  1260\n",
      "1    43   188\n",
      "\n",
      "Detailed cross-validation scores:\n",
      "    mean_test_score  std_test_score\n",
      "0          0.000000        0.000000\n",
      "1          0.000000        0.000000\n",
      "2          0.027469        0.010256\n",
      "3          0.014017        0.003945\n",
      "4          0.216220        0.006385\n",
      "5          0.216220        0.006385\n",
      "6          0.223104        0.007070\n",
      "7          0.222852        0.006794\n",
      "8          0.055220        0.010819\n",
      "9          0.054066        0.022379\n",
      "10         0.188820        0.029501\n",
      "11         0.189073        0.029375\n",
      "12         0.217913        0.007325\n",
      "13         0.217913        0.007325\n",
      "14         0.226903        0.005436\n",
      "15         0.226948        0.005488\n",
      "16         0.228263        0.023634\n",
      "17         0.228263        0.023634\n",
      "18         0.218577        0.016618\n",
      "19         0.219435        0.017736\n",
      "20         0.231542        0.004639\n",
      "21         0.231498        0.004673\n",
      "22         0.233819        0.004935\n",
      "23         0.233772        0.004965\n",
      "24         0.215851        0.008796\n",
      "25         0.215741        0.008907\n",
      "26         0.218286        0.010816\n",
      "27         0.218176        0.010928\n",
      "28         0.228804        0.003754\n",
      "29         0.228753        0.003809\n",
      "30         0.229430        0.003940\n",
      "31         0.229430        0.003940\n",
      "32         0.211533        0.012455\n",
      "33         0.215064        0.012969\n",
      "34         0.214238        0.013378\n",
      "35         0.214130        0.013438\n",
      "36         0.227873        0.004516\n",
      "37         0.228634        0.004584\n",
      "38         0.228634        0.004584\n",
      "39         0.228681        0.004589\n",
      "\n",
      "SMOTE config: {'smote': None, 'under_sampler': RandomUnderSampler(random_state=42, sampling_strategy=0.3)}, CV: 4\n",
      "Best parameters: {'classifier__C': 1, 'classifier__class_weight': 'balanced', 'classifier__penalty': 'l2', 'classifier__solver': 'liblinear'}\n",
      "Best cross-validation score: 0.23341287526345605\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.65      0.78      3624\n",
      "           1       0.13      0.81      0.22       231\n",
      "\n",
      "    accuracy                           0.66      3855\n",
      "   macro avg       0.56      0.73      0.50      3855\n",
      "weighted avg       0.93      0.66      0.75      3855\n",
      "\n",
      "      0     1\n",
      "0  2364  1260\n",
      "1    43   188\n",
      "\n",
      "Detailed cross-validation scores:\n",
      "    mean_test_score  std_test_score\n",
      "0          0.000000        0.000000\n",
      "1          0.000000        0.000000\n",
      "2          0.031990        0.027184\n",
      "3          0.019142        0.016077\n",
      "4          0.216397        0.010207\n",
      "5          0.216397        0.010207\n",
      "6          0.222182        0.013355\n",
      "7          0.222000        0.013805\n",
      "8          0.060157        0.013901\n",
      "9          0.047751        0.025723\n",
      "10         0.197603        0.016268\n",
      "11         0.197729        0.016440\n",
      "12         0.219531        0.012580\n",
      "13         0.219531        0.012580\n",
      "14         0.228028        0.012257\n",
      "15         0.227945        0.012280\n",
      "16         0.206294        0.010784\n",
      "17         0.206186        0.010827\n",
      "18         0.212350        0.013218\n",
      "19         0.212453        0.013332\n",
      "20         0.231155        0.010330\n",
      "21         0.230791        0.010329\n",
      "22         0.233413        0.012264\n",
      "23         0.233413        0.012264\n",
      "24         0.214239        0.009723\n",
      "25         0.214140        0.009647\n",
      "26         0.215247        0.011227\n",
      "27         0.215346        0.011151\n",
      "28         0.227499        0.013051\n",
      "29         0.227881        0.012522\n",
      "30         0.229020        0.011670\n",
      "31         0.229020        0.011670\n",
      "32         0.214198        0.011216\n",
      "33         0.214225        0.011276\n",
      "34         0.214093        0.011100\n",
      "35         0.214879        0.011820\n",
      "36         0.227714        0.013097\n",
      "37         0.227816        0.013168\n",
      "38         0.227943        0.013057\n",
      "39         0.227992        0.013065\n",
      "\n",
      "SMOTE config: {'smote': None, 'under_sampler': RandomUnderSampler(random_state=42, sampling_strategy=0.3)}, CV: 5\n",
      "Best parameters: {'classifier__C': 1, 'classifier__class_weight': 'balanced', 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n",
      "Best cross-validation score: 0.23717469028770868\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.65      0.78      3624\n",
      "           1       0.13      0.81      0.22       231\n",
      "\n",
      "    accuracy                           0.66      3855\n",
      "   macro avg       0.56      0.73      0.50      3855\n",
      "weighted avg       0.93      0.66      0.75      3855\n",
      "\n",
      "      0     1\n",
      "0  2364  1260\n",
      "1    43   188\n",
      "\n",
      "Detailed cross-validation scores:\n",
      "    mean_test_score  std_test_score\n",
      "0          0.000000        0.000000\n",
      "1          0.000000        0.000000\n",
      "2          0.029203        0.022647\n",
      "3          0.016369        0.015900\n",
      "4          0.216354        0.010832\n",
      "5          0.216354        0.010832\n",
      "6          0.225648        0.013855\n",
      "7          0.225275        0.013627\n",
      "8          0.061612        0.029308\n",
      "9          0.051732        0.031477\n",
      "10         0.185721        0.022798\n",
      "11         0.185943        0.022762\n",
      "12         0.218358        0.013253\n",
      "13         0.218358        0.013253\n",
      "14         0.232725        0.013262\n",
      "15         0.232725        0.013262\n",
      "16         0.205157        0.010030\n",
      "17         0.205059        0.010198\n",
      "18         0.207602        0.016010\n",
      "19         0.208381        0.015770\n",
      "20         0.235711        0.015809\n",
      "21         0.235658        0.015743\n",
      "22         0.237122        0.017564\n",
      "23         0.237175        0.017595\n",
      "24         0.209568        0.015806\n",
      "25         0.209300        0.014319\n",
      "26         0.210088        0.015031\n",
      "27         0.209991        0.015051\n",
      "28         0.235902        0.016555\n",
      "29         0.235594        0.017219\n",
      "30         0.235969        0.016865\n",
      "31         0.235969        0.016865\n",
      "32         0.211881        0.016029\n",
      "33         0.212024        0.016225\n",
      "34         0.212026        0.016235\n",
      "35         0.211940        0.016375\n",
      "36         0.235207        0.017993\n",
      "37         0.235142        0.017869\n",
      "38         0.235299        0.017914\n",
      "39         0.235248        0.017917\n",
      "\n",
      "SMOTE config: {'smote': None, 'under_sampler': RandomUnderSampler(random_state=42, sampling_strategy=0.2)}, CV: 3\n",
      "Best parameters: {'classifier__C': 1, 'classifier__class_weight': 'balanced', 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "Best cross-validation score: 0.2342072530754092\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.65      0.78      3624\n",
      "           1       0.12      0.79      0.22       231\n",
      "\n",
      "    accuracy                           0.66      3855\n",
      "   macro avg       0.55      0.72      0.50      3855\n",
      "weighted avg       0.93      0.66      0.75      3855\n",
      "\n",
      "      0     1\n",
      "0  2347  1277\n",
      "1    49   182\n",
      "\n",
      "Detailed cross-validation scores:\n",
      "    mean_test_score  std_test_score\n",
      "0          0.000000        0.000000\n",
      "1          0.000000        0.000000\n",
      "2          0.002874        0.004064\n",
      "3          0.000000        0.000000\n",
      "4          0.216220        0.006385\n",
      "5          0.216220        0.006385\n",
      "6          0.223990        0.007588\n",
      "7          0.224123        0.007710\n",
      "8          0.024055        0.000750\n",
      "9          0.021452        0.003105\n",
      "10         0.105584        0.011351\n",
      "11         0.105478        0.011454\n",
      "12         0.220052        0.006439\n",
      "13         0.220052        0.006439\n",
      "14         0.231022        0.005382\n",
      "15         0.231022        0.005382\n",
      "16         0.151563        0.025381\n",
      "17         0.154881        0.027179\n",
      "18         0.166016        0.025126\n",
      "19         0.166153        0.025063\n",
      "20         0.234207        0.005054\n",
      "21         0.234158        0.004997\n",
      "22         0.233624        0.007108\n",
      "23         0.233624        0.007108\n",
      "24         0.177472        0.024374\n",
      "25         0.177472        0.024374\n",
      "26         0.174721        0.025501\n",
      "27         0.174721        0.025501\n",
      "28         0.231152        0.006967\n",
      "29         0.231101        0.006895\n",
      "30         0.231564        0.006922\n",
      "31         0.231458        0.006980\n",
      "32         0.176184        0.024481\n",
      "33         0.176517        0.025204\n",
      "34         0.176396        0.025284\n",
      "35         0.176396        0.025284\n",
      "36         0.230389        0.007124\n",
      "37         0.230644        0.007757\n",
      "38         0.231010        0.007585\n",
      "39         0.231005        0.007478\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE config: {'smote': None, 'under_sampler': RandomUnderSampler(random_state=42, sampling_strategy=0.2)}, CV: 4\n",
      "Best parameters: {'classifier__C': 1, 'classifier__class_weight': 'balanced', 'classifier__penalty': 'l2', 'classifier__solver': 'liblinear'}\n",
      "Best cross-validation score: 0.2343960451982317\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.65      0.78      3624\n",
      "           1       0.13      0.78      0.22       231\n",
      "\n",
      "    accuracy                           0.66      3855\n",
      "   macro avg       0.55      0.72      0.50      3855\n",
      "weighted avg       0.93      0.66      0.75      3855\n",
      "\n",
      "      0     1\n",
      "0  2369  1255\n",
      "1    51   180\n",
      "\n",
      "Detailed cross-validation scores:\n",
      "    mean_test_score  std_test_score\n",
      "0          0.000000        0.000000\n",
      "1          0.000000        0.000000\n",
      "2          0.000000        0.000000\n",
      "3          0.000000        0.000000\n",
      "4          0.216397        0.010207\n",
      "5          0.216397        0.010207\n",
      "6          0.225033        0.013584\n",
      "7          0.223867        0.014698\n",
      "8          0.038559        0.010644\n",
      "9          0.028411        0.019303\n",
      "10         0.102316        0.022387\n",
      "11         0.102203        0.022358\n",
      "12         0.221730        0.012009\n",
      "13         0.221730        0.012009\n",
      "14         0.228376        0.010932\n",
      "15         0.228330        0.010914\n",
      "16         0.154813        0.015339\n",
      "17         0.156124        0.016321\n",
      "18         0.166520        0.023079\n",
      "19         0.164864        0.022364\n",
      "20         0.231028        0.009322\n",
      "21         0.231076        0.009350\n",
      "22         0.234396        0.010613\n",
      "23         0.234396        0.010613\n",
      "24         0.173599        0.024332\n",
      "25         0.173720        0.024176\n",
      "26         0.175749        0.022749\n",
      "27         0.175860        0.022676\n",
      "28         0.233762        0.011927\n",
      "29         0.233762        0.011927\n",
      "30         0.233732        0.012030\n",
      "31         0.233732        0.012030\n",
      "32         0.175794        0.023281\n",
      "33         0.175686        0.023377\n",
      "34         0.175667        0.023043\n",
      "35         0.175667        0.023043\n",
      "36         0.234057        0.011489\n",
      "37         0.234109        0.011522\n",
      "38         0.234080        0.011727\n",
      "39         0.234080        0.011727\n",
      "\n",
      "SMOTE config: {'smote': None, 'under_sampler': RandomUnderSampler(random_state=42, sampling_strategy=0.2)}, CV: 5\n",
      "Best parameters: {'classifier__C': 1, 'classifier__class_weight': 'balanced', 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "Best cross-validation score: 0.23676474802002864\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.65      0.78      3624\n",
      "           1       0.12      0.79      0.22       231\n",
      "\n",
      "    accuracy                           0.66      3855\n",
      "   macro avg       0.55      0.72      0.50      3855\n",
      "weighted avg       0.93      0.66      0.75      3855\n",
      "\n",
      "      0     1\n",
      "0  2347  1277\n",
      "1    49   182\n",
      "\n",
      "Detailed cross-validation scores:\n",
      "    mean_test_score  std_test_score\n",
      "0          0.000000        0.000000\n",
      "1          0.000000        0.000000\n",
      "2          0.000000        0.000000\n",
      "3          0.000000        0.000000\n",
      "4          0.216354        0.010832\n",
      "5          0.216354        0.010832\n",
      "6          0.223286        0.013350\n",
      "7          0.223440        0.013284\n",
      "8          0.034135        0.010528\n",
      "9          0.028799        0.012455\n",
      "10         0.102882        0.028282\n",
      "11         0.102882        0.028282\n",
      "12         0.220822        0.011134\n",
      "13         0.220822        0.011134\n",
      "14         0.233797        0.011248\n",
      "15         0.233797        0.011248\n",
      "16         0.156686        0.021759\n",
      "17         0.158517        0.022339\n",
      "18         0.171471        0.024212\n",
      "19         0.171471        0.024212\n",
      "20         0.236765        0.013882\n",
      "21         0.236765        0.013882\n",
      "22         0.236600        0.017056\n",
      "23         0.236600        0.017056\n",
      "24         0.173027        0.016284\n",
      "25         0.174940        0.017509\n",
      "26         0.176209        0.014108\n",
      "27         0.176209        0.014108\n",
      "28         0.234993        0.017989\n",
      "29         0.235041        0.017967\n",
      "30         0.235655        0.017763\n",
      "31         0.235655        0.017763\n",
      "32         0.176116        0.011698\n",
      "33         0.176540        0.011856\n",
      "34         0.176540        0.011856\n",
      "35         0.175062        0.013937\n",
      "36         0.234891        0.017917\n",
      "37         0.235097        0.018001\n",
      "38         0.235303        0.018085\n",
      "39         0.235210        0.018118\n",
      "\n",
      "SMOTE config: {'smote': SMOTE(random_state=42, sampling_strategy=1.0), 'under_sampler': RandomUnderSampler(random_state=42, sampling_strategy=0.5)}, CV: 3\n",
      "Best parameters: {'classifier__C': 1, 'classifier__class_weight': 'balanced', 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "Best cross-validation score: 0.22703157648799274\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.66      0.79      3624\n",
      "           1       0.13      0.77      0.22       231\n",
      "\n",
      "    accuracy                           0.67      3855\n",
      "   macro avg       0.55      0.72      0.51      3855\n",
      "weighted avg       0.93      0.67      0.76      3855\n",
      "\n",
      "      0     1\n",
      "0  2409  1215\n",
      "1    53   178\n",
      "\n",
      "Detailed cross-validation scores:\n",
      "    mean_test_score  std_test_score\n",
      "0          0.216220        0.006385\n",
      "1          0.216220        0.006385\n",
      "2          0.222203        0.008562\n",
      "3          0.222610        0.008791\n",
      "4          0.215960        0.006318\n",
      "5          0.216220        0.006385\n",
      "6          0.222203        0.008562\n",
      "7          0.222610        0.008791\n",
      "8          0.219048        0.007180\n",
      "9          0.219048        0.007180\n",
      "10         0.226125        0.006523\n",
      "11         0.226083        0.006583\n",
      "12         0.219048        0.007180\n",
      "13         0.219048        0.007180\n",
      "14         0.226125        0.006523\n",
      "15         0.226083        0.006583\n",
      "16         0.226886        0.001346\n",
      "17         0.226985        0.001399\n",
      "18         0.224939        0.006000\n",
      "19         0.224892        0.005999\n",
      "20         0.227032        0.001346\n",
      "21         0.226985        0.001399\n",
      "22         0.224939        0.006000\n",
      "23         0.224892        0.005999\n",
      "24         0.225361        0.005057\n",
      "25         0.225033        0.005238\n",
      "26         0.225707        0.006005\n",
      "27         0.225657        0.005940\n",
      "28         0.224984        0.005170\n",
      "29         0.225033        0.005238\n",
      "30         0.225707        0.006005\n",
      "31         0.225657        0.005940\n",
      "32         0.223773        0.006074\n",
      "33         0.225178        0.006065\n",
      "34         0.225232        0.005807\n",
      "35         0.225515        0.006326\n",
      "36         0.223878        0.005966\n",
      "37         0.225178        0.006065\n",
      "38         0.225232        0.005807\n",
      "39         0.225515        0.006326\n",
      "\n",
      "SMOTE config: {'smote': SMOTE(random_state=42, sampling_strategy=1.0), 'under_sampler': RandomUnderSampler(random_state=42, sampling_strategy=0.5)}, CV: 4\n",
      "Best parameters: {'classifier__C': 1, 'classifier__class_weight': None, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "Best cross-validation score: 0.2294207644238632\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.66      0.79      3624\n",
      "           1       0.13      0.77      0.22       231\n",
      "\n",
      "    accuracy                           0.67      3855\n",
      "   macro avg       0.55      0.72      0.51      3855\n",
      "weighted avg       0.93      0.67      0.76      3855\n",
      "\n",
      "      0     1\n",
      "0  2409  1215\n",
      "1    53   178\n",
      "\n",
      "Detailed cross-validation scores:\n",
      "    mean_test_score  std_test_score\n",
      "0          0.216397        0.010207\n",
      "1          0.216397        0.010207\n",
      "2          0.221125        0.012758\n",
      "3          0.220775        0.013606\n",
      "4          0.216397        0.010207\n",
      "5          0.216397        0.010207\n",
      "6          0.221125        0.012758\n",
      "7          0.220817        0.013634\n",
      "8          0.216802        0.010989\n",
      "9          0.216802        0.010989\n",
      "10         0.227487        0.013134\n",
      "11         0.227569        0.013081\n",
      "12         0.216802        0.010989\n",
      "13         0.216802        0.010989\n",
      "14         0.227487        0.013134\n",
      "15         0.227569        0.013081\n",
      "16         0.229421        0.009528\n",
      "17         0.229287        0.008749\n",
      "18         0.228201        0.007820\n",
      "19         0.228201        0.007820\n",
      "20         0.229421        0.009528\n",
      "21         0.229287        0.008749\n",
      "22         0.228201        0.007820\n",
      "23         0.228201        0.007820\n",
      "24         0.225993        0.007274\n",
      "25         0.225946        0.007323\n",
      "26         0.226489        0.007109\n",
      "27         0.226489        0.007109\n",
      "28         0.226044        0.007290\n",
      "29         0.225946        0.007323\n",
      "30         0.226489        0.007109\n",
      "31         0.226489        0.007109\n",
      "32         0.224331        0.006946\n",
      "33         0.223800        0.006837\n",
      "34         0.223518        0.006684\n",
      "35         0.223427        0.006741\n",
      "36         0.224331        0.006946\n",
      "37         0.223800        0.006837\n",
      "38         0.223518        0.006684\n",
      "39         0.223427        0.006741\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE config: {'smote': SMOTE(random_state=42, sampling_strategy=1.0), 'under_sampler': RandomUnderSampler(random_state=42, sampling_strategy=0.5)}, CV: 5\n",
      "Best parameters: {'classifier__C': 1, 'classifier__class_weight': None, 'classifier__penalty': 'l2', 'classifier__solver': 'liblinear'}\n",
      "Best cross-validation score: 0.23049663163779338\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.67      0.80      3624\n",
      "           1       0.13      0.77      0.22       231\n",
      "\n",
      "    accuracy                           0.68      3855\n",
      "   macro avg       0.55      0.72      0.51      3855\n",
      "weighted avg       0.93      0.68      0.76      3855\n",
      "\n",
      "      0     1\n",
      "0  2427  1197\n",
      "1    54   177\n",
      "\n",
      "Detailed cross-validation scores:\n",
      "    mean_test_score  std_test_score\n",
      "0          0.216354        0.010832\n",
      "1          0.216354        0.010832\n",
      "2          0.222480        0.013437\n",
      "3          0.222243        0.014433\n",
      "4          0.216354        0.010832\n",
      "5          0.216354        0.010832\n",
      "6          0.222480        0.013437\n",
      "7          0.222245        0.014443\n",
      "8          0.217735        0.014416\n",
      "9          0.217735        0.014416\n",
      "10         0.229894        0.016145\n",
      "11         0.229894        0.016145\n",
      "12         0.217735        0.014416\n",
      "13         0.217735        0.014416\n",
      "14         0.229894        0.016145\n",
      "15         0.229934        0.016079\n",
      "16         0.229987        0.015388\n",
      "17         0.230040        0.015452\n",
      "18         0.230497        0.017528\n",
      "19         0.230497        0.017528\n",
      "20         0.230040        0.015452\n",
      "21         0.230040        0.015452\n",
      "22         0.230497        0.017528\n",
      "23         0.230497        0.017528\n",
      "24         0.228892        0.019035\n",
      "25         0.228861        0.019238\n",
      "26         0.229526        0.017984\n",
      "27         0.229526        0.017984\n",
      "28         0.228892        0.019035\n",
      "29         0.228861        0.019238\n",
      "30         0.229526        0.017984\n",
      "31         0.229526        0.017984\n",
      "32         0.228534        0.019053\n",
      "33         0.228193        0.019151\n",
      "34         0.228035        0.019115\n",
      "35         0.228146        0.019226\n",
      "36         0.228534        0.019053\n",
      "37         0.228193        0.019151\n",
      "38         0.228035        0.019115\n",
      "39         0.228146        0.019226\n",
      "\n",
      "\n",
      "Best overall result:\n",
      "SMOTE config: {'smote': None, 'under_sampler': RandomUnderSampler(random_state=42, sampling_strategy=0.5)}, CV: 5\n",
      "Best parameters: {'classifier__C': 1, 'classifier__class_weight': None, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "Best cross-validation score: 0.25042774059626377\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3624.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.22</td>\n",
       "      <td>231.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.54</td>\n",
       "      <td>3855.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.82</td>\n",
       "      <td>3855.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision  recall  f1-score  support\n",
       "0                  0.96    0.78      0.86  3624.00\n",
       "1                  0.14    0.55      0.22   231.00\n",
       "accuracy           0.77    0.77      0.77     0.77\n",
       "macro avg          0.55    0.67      0.54  3855.00\n",
       "weighted avg       0.91    0.77      0.82  3855.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0    1\n",
      "0  2829  795\n",
      "1   104  127\n",
      "\n",
      "Worst overall result:\n",
      "SMOTE config: {'smote': SMOTE(random_state=42, sampling_strategy=1.0), 'under_sampler': RandomUnderSampler(random_state=42, sampling_strategy=0.5)}, CV: 3\n",
      "Best parameters: {'classifier__C': 1, 'classifier__class_weight': 'balanced', 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "Best cross-validation score: 0.22703157648799274\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.79</td>\n",
       "      <td>3624.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.13</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.22</td>\n",
       "      <td>231.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.51</td>\n",
       "      <td>3855.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.93</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.76</td>\n",
       "      <td>3855.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision  recall  f1-score  support\n",
       "0                  0.98    0.66      0.79  3624.00\n",
       "1                  0.13    0.77      0.22   231.00\n",
       "accuracy           0.67    0.67      0.67     0.67\n",
       "macro avg          0.55    0.72      0.51  3855.00\n",
       "weighted avg       0.93    0.67      0.76  3855.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0     1\n",
      "0  2409  1215\n",
      "1    53   178\n"
     ]
    }
   ],
   "source": [
    "# Load the data \n",
    "data = pd.read_csv('fraud_vihecles.csv')\n",
    "\n",
    "# Set X and y\n",
    "X = data.drop(columns=['FraudFound_P'])\n",
    "y = data['FraudFound_P']\n",
    "\n",
    "# Split the data with stratification on the target column\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, stratify=y, random_state=42)\n",
    "\n",
    "# List of columns to drop\n",
    "columns_to_drop = ['PolicyNumber', 'Age'] #'WeekOfMonth', 'DayOfWeek', 'RepNumber', \n",
    "\n",
    "# Define the preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('drop_columns', 'drop', columns_to_drop),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), X_train.columns.difference(columns_to_drop))\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'classifier__C': [0.01, 0.1, 1, 10, 100], # , 1, 10, 100 were tried and they are not effective\n",
    "    'classifier__penalty': ['l1', 'l2'],\n",
    "    'classifier__solver': ['liblinear', 'saga'],\n",
    "    'classifier__class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "# SMOTE and under-sampling configurations based on the requirements\n",
    "smote_configs = [\n",
    "    # 1. Keep the original class proportion\n",
    "    {'smote': None, 'under_sampler': None},\n",
    "    \n",
    "    # 2. Keep the same fraud, downsample non-fraudulent rows by 40%\n",
    "    {'smote': None, 'under_sampler': RandomUnderSampler(sampling_strategy=0.6, random_state=42)},\n",
    "    \n",
    "    # 3. Keep the same fraud, downsample non-fraudulent rows by 50%\n",
    "    {'smote': None, 'under_sampler': RandomUnderSampler(sampling_strategy=0.5, random_state=42)},\n",
    "    \n",
    "    # 4. Keep the same fraud, downsample non-fraudulent rows by 60%\n",
    "    {'smote': None, 'under_sampler': RandomUnderSampler(sampling_strategy=0.4, random_state=42)},\n",
    "    \n",
    "    # 5. Keep the same fraud, downsample non-fraudulent rows by 70%\n",
    "    {'smote': None, 'under_sampler': RandomUnderSampler(sampling_strategy=0.3, random_state=42)},\n",
    "    \n",
    "    # 6. Keep the same fraud, downsample non-fraudulent rows by 80%\n",
    "    {'smote': None, 'under_sampler': RandomUnderSampler(sampling_strategy=0.2, random_state=42)},\n",
    "    \n",
    "    # 7. Increase fraud by 100%, downsample non-fraudulent rows by 50%\n",
    "    {'smote': SMOTE(sampling_strategy=1.0, random_state=42), 'under_sampler': RandomUnderSampler(sampling_strategy=0.5, random_state=42)}\n",
    "]\n",
    "\n",
    "# Cross-validation strategies\n",
    "cv_strategies = [3, 4, 5]\n",
    "\n",
    "best_results = []\n",
    "\n",
    "# Define the F-beta scorer with beta=1.0 (F1 score)\n",
    "fbeta_scorer = make_scorer(fbeta_score, beta=1.0, pos_label=1)\n",
    "\n",
    "# Loop through SMOTE configurations and CV strategies\n",
    "for smote_config in smote_configs:\n",
    "    for cv in cv_strategies:\n",
    "        pipeline = ImbPipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('under_sampler', smote_config['under_sampler']),\n",
    "            ('smote', smote_config['smote']),\n",
    "            ('classifier', LogisticRegression(max_iter=1000, class_weight='balanced'))\n",
    "        ])\n",
    "        \n",
    "        \n",
    "        grid_search = GridSearchCV(pipeline, param_grid, cv=cv, scoring=fbeta_scorer, n_jobs=-1)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        \n",
    "        best_params = grid_search.best_params_\n",
    "        best_score = grid_search.best_score_\n",
    "        \n",
    "        y_pred = grid_search.predict(X_test)\n",
    "        report = classification_report(y_test, y_pred, output_dict=True)\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        \n",
    "        best_results.append({\n",
    "            'smote_config': smote_config,\n",
    "            'cv': cv,\n",
    "            'best_params': best_params,\n",
    "            'best_score': best_score,\n",
    "            'classification_report': report,\n",
    "            'confusion_matrix': cm\n",
    "        })\n",
    "        \n",
    "        print(f\"SMOTE config: {smote_config}, CV: {cv}\")\n",
    "        print(f\"Best parameters: {best_params}\")\n",
    "        print(f\"Best cross-validation score: {best_score}\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        print(pd.DataFrame(cm, index=grid_search.classes_, columns=grid_search.classes_))\n",
    "        \n",
    "        print(\"\\nDetailed cross-validation scores:\")\n",
    "        cv_results = pd.DataFrame(grid_search.cv_results_)\n",
    "        print(cv_results[['mean_test_score', 'std_test_score']])\n",
    "        print()\n",
    "\n",
    "# Find the best overall result\n",
    "best_result = max(best_results, key=lambda x: x['best_score'])\n",
    "\n",
    "print(\"\\nBest overall result:\")\n",
    "print(f\"SMOTE config: {best_result['smote_config']}, CV: {best_result['cv']}\")\n",
    "print(f\"Best parameters: {best_result['best_params']}\")\n",
    "print(f\"Best cross-validation score: {best_result['best_score']}\")\n",
    "display(pd.DataFrame(best_result['classification_report']).transpose().round(2))\n",
    "print(pd.DataFrame(best_result['confusion_matrix'], index=grid_search.classes_, columns=grid_search.classes_))\n",
    "\n",
    "# Find the worst overall result\n",
    "worst_result = min(best_results, key=lambda x: x['best_score'])\n",
    "\n",
    "print(\"\\nWorst overall result:\")\n",
    "print(f\"SMOTE config: {worst_result['smote_config']}, CV: {worst_result['cv']}\")\n",
    "print(f\"Best parameters: {worst_result['best_params']}\")\n",
    "print(f\"Best cross-validation score: {worst_result['best_score']}\")\n",
    "display(pd.DataFrame(worst_result['classification_report']).transpose().round(2))\n",
    "print(pd.DataFrame(worst_result['confusion_matrix'], index=grid_search.classes_, columns=grid_search.classes_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71157a66",
   "metadata": {},
   "source": [
    "## 5. Modeling with Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6ff127",
   "metadata": {},
   "source": [
    "#### 5.1 Building a benchmark model to take a look what we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "11fcf20c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-50 {color: black;}#sk-container-id-50 pre{padding: 0;}#sk-container-id-50 div.sk-toggleable {background-color: white;}#sk-container-id-50 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-50 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-50 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-50 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-50 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-50 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-50 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-50 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-50 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-50 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-50 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-50 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-50 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-50 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-50 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-50 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-50 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-50 div.sk-item {position: relative;z-index: 1;}#sk-container-id-50 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-50 div.sk-item::before, #sk-container-id-50 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-50 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-50 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-50 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-50 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-50 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-50 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-50 div.sk-label-container {text-align: center;}#sk-container-id-50 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-50 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-50\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-50\" type=\"checkbox\" checked><label for=\"sk-estimator-id-50\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(random_state=42)"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, let's instantiate the model\n",
    "dtc = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Let's fit the model\n",
    "dtc.fit(X_train_encoded, y_train)\n",
    "#dtc.fit(X_train_label_encoded, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "3f793558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0    1\n",
      "0  10873    0\n",
      "1      0  692\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     10873\n",
      "           1       1.00      1.00      1.00       692\n",
      "\n",
      "    accuracy                           1.00     11565\n",
      "   macro avg       1.00      1.00      1.00     11565\n",
      "weighted avg       1.00      1.00      1.00     11565\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Running on train data\n",
    "cm = confusion_matrix(y_true=y_train,\n",
    "                      y_pred=dtc.predict(X_train_encoded))\n",
    "print(pd.DataFrame(cm,\n",
    "             index=dtc.classes_,\n",
    "             columns=dtc.classes_))\n",
    "\n",
    "print(classification_report(y_train, dtc.predict(X_train_encoded)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "2ffeb753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0    1\n",
      "0  3418  206\n",
      "1   194   37\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.94      3624\n",
      "           1       0.15      0.16      0.16       231\n",
      "\n",
      "    accuracy                           0.90      3855\n",
      "   macro avg       0.55      0.55      0.55      3855\n",
      "weighted avg       0.90      0.90      0.90      3855\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Running on test data\n",
    "cm = confusion_matrix(y_true=y_test,\n",
    "                      y_pred=dtc.predict(X_test_encoded))\n",
    "print(pd.DataFrame(cm,\n",
    "             index=dtc.classes_,\n",
    "             columns=dtc.classes_))\n",
    "print(classification_report(y_test, dtc.predict(X_test_encoded)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "cf50d4b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get feature importances\n",
    "feature_importances = dtc.feature_importances_\n",
    "\n",
    "# Create a DataFrame for better readability\n",
    "feature_names = X_train_encoded.columns\n",
    "feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
    "\n",
    "# Sort the DataFrame by importance\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Select the top 20 features\n",
    "top_20_features = feature_importance_df.head(20)\n",
    "\n",
    "# Plot the feature importances\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.barh(top_20_features['Feature'], top_20_features['Importance'])\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Top 20 Feature Importances')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477939f1",
   "metadata": {},
   "source": [
    "#### 5.2 Pipeline with gridsearch and finding the best hyperparameters and learning the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f7f65fe6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE config: {'smote': None, 'under_sampler': None}, CV: 3\n",
      "Best parameters: {'classifier__class_weight': 'balanced', 'classifier__max_depth': 15, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}\n",
      "Best cross-validation score: 0.24069085088798117\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.70      0.82      3624\n",
      "           1       0.13      0.72      0.23       231\n",
      "\n",
      "    accuracy                           0.71      3855\n",
      "   macro avg       0.56      0.71      0.52      3855\n",
      "weighted avg       0.93      0.71      0.78      3855\n",
      "\n",
      "      0     1\n",
      "0  2552  1072\n",
      "1    64   167\n",
      "\n",
      "Detailed cross-validation scores:\n",
      "    mean_test_score  std_test_score\n",
      "0          0.072050        0.039749\n",
      "1          0.072050        0.039749\n",
      "2          0.072422        0.039873\n",
      "3          0.072632        0.039700\n",
      "4          0.072632        0.039700\n",
      "..              ...             ...\n",
      "91         0.238789        0.006040\n",
      "92         0.238789        0.006040\n",
      "93         0.231192        0.010057\n",
      "94         0.231192        0.010057\n",
      "95         0.231192        0.010057\n",
      "\n",
      "[96 rows x 2 columns]\n",
      "\n",
      "SMOTE config: {'smote': None, 'under_sampler': None}, CV: 4\n",
      "Best parameters: {'classifier__class_weight': 'balanced', 'classifier__max_depth': 15, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 3}\n",
      "Best cross-validation score: 0.24159571011478917\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.70      0.82      3624\n",
      "           1       0.13      0.71      0.22       231\n",
      "\n",
      "    accuracy                           0.70      3855\n",
      "   macro avg       0.55      0.71      0.52      3855\n",
      "weighted avg       0.92      0.70      0.78      3855\n",
      "\n",
      "      0     1\n",
      "0  2552  1072\n",
      "1    66   165\n",
      "\n",
      "Detailed cross-validation scores:\n",
      "    mean_test_score  std_test_score\n",
      "0          0.067657        0.047713\n",
      "1          0.067509        0.047754\n",
      "2          0.065096        0.050193\n",
      "3          0.065000        0.050274\n",
      "4          0.065000        0.050274\n",
      "..              ...             ...\n",
      "91         0.233004        0.014844\n",
      "92         0.233004        0.014844\n",
      "93         0.237553        0.009911\n",
      "94         0.237553        0.009911\n",
      "95         0.237553        0.009911\n",
      "\n",
      "[96 rows x 2 columns]\n",
      "\n",
      "SMOTE config: {'smote': None, 'under_sampler': None}, CV: 5\n",
      "Best parameters: {'classifier__class_weight': 'balanced', 'classifier__max_depth': 15, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}\n",
      "Best cross-validation score: 0.2531842705129145\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.70      0.82      3624\n",
      "           1       0.13      0.72      0.23       231\n",
      "\n",
      "    accuracy                           0.71      3855\n",
      "   macro avg       0.56      0.71      0.52      3855\n",
      "weighted avg       0.93      0.71      0.78      3855\n",
      "\n",
      "      0     1\n",
      "0  2552  1072\n",
      "1    64   167\n",
      "\n",
      "Detailed cross-validation scores:\n",
      "    mean_test_score  std_test_score\n",
      "0          0.072486        0.055481\n",
      "1          0.072413        0.055505\n",
      "2          0.072727        0.055960\n",
      "3          0.072962        0.055831\n",
      "4          0.072962        0.055831\n",
      "..              ...             ...\n",
      "91         0.243456        0.003168\n",
      "92         0.243456        0.003168\n",
      "93         0.241706        0.009946\n",
      "94         0.241706        0.009946\n",
      "95         0.241706        0.009946\n",
      "\n",
      "[96 rows x 2 columns]\n",
      "\n",
      "SMOTE config: {'smote': None, 'under_sampler': RandomUnderSampler(random_state=42, sampling_strategy=0.6)}, CV: 3\n",
      "Best parameters: {'classifier__class_weight': None, 'classifier__max_depth': 5, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}\n",
      "Best cross-validation score: 0.24788666924927347\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.63      0.77      3624\n",
      "           1       0.12      0.81      0.21       231\n",
      "\n",
      "    accuracy                           0.64      3855\n",
      "   macro avg       0.55      0.72      0.49      3855\n",
      "weighted avg       0.93      0.64      0.74      3855\n",
      "\n",
      "      0     1\n",
      "0  2292  1332\n",
      "1    45   186\n",
      "\n",
      "Detailed cross-validation scores:\n",
      "    mean_test_score  std_test_score\n",
      "0          0.244629        0.025681\n",
      "1          0.244629        0.025681\n",
      "2          0.244915        0.026426\n",
      "3          0.243713        0.026335\n",
      "4          0.243713        0.026335\n",
      "..              ...             ...\n",
      "91         0.232295        0.009245\n",
      "92         0.232295        0.009245\n",
      "93         0.237964        0.011042\n",
      "94         0.237964        0.011042\n",
      "95         0.237964        0.011042\n",
      "\n",
      "[96 rows x 2 columns]\n",
      "\n",
      "SMOTE config: {'smote': None, 'under_sampler': RandomUnderSampler(random_state=42, sampling_strategy=0.6)}, CV: 4\n",
      "Best parameters: {'classifier__class_weight': None, 'classifier__max_depth': 7, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}\n",
      "Best cross-validation score: 0.2387651294930124\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.64      0.77      3624\n",
      "           1       0.12      0.80      0.21       231\n",
      "\n",
      "    accuracy                           0.65      3855\n",
      "   macro avg       0.55      0.72      0.49      3855\n",
      "weighted avg       0.93      0.65      0.74      3855\n",
      "\n",
      "      0     1\n",
      "0  2318  1306\n",
      "1    47   184\n",
      "\n",
      "Detailed cross-validation scores:\n",
      "    mean_test_score  std_test_score\n",
      "0          0.223012        0.006673\n",
      "1          0.223219        0.006816\n",
      "2          0.223852        0.006734\n",
      "3          0.221492        0.006812\n",
      "4          0.221492        0.006812\n",
      "..              ...             ...\n",
      "91         0.229031        0.009777\n",
      "92         0.229031        0.009777\n",
      "93         0.223696        0.006704\n",
      "94         0.223696        0.006704\n",
      "95         0.223696        0.006704\n",
      "\n",
      "[96 rows x 2 columns]\n",
      "\n",
      "SMOTE config: {'smote': None, 'under_sampler': RandomUnderSampler(random_state=42, sampling_strategy=0.6)}, CV: 5\n",
      "Best parameters: {'classifier__class_weight': None, 'classifier__max_depth': 7, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}\n",
      "Best cross-validation score: 0.260644821386533\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.64      0.77      3624\n",
      "           1       0.13      0.84      0.22       231\n",
      "\n",
      "    accuracy                           0.65      3855\n",
      "   macro avg       0.56      0.74      0.50      3855\n",
      "weighted avg       0.93      0.65      0.74      3855\n",
      "\n",
      "      0     1\n",
      "0  2302  1322\n",
      "1    36   195\n",
      "\n",
      "Detailed cross-validation scores:\n",
      "    mean_test_score  std_test_score\n",
      "0          0.244491        0.008700\n",
      "1          0.244491        0.008700\n",
      "2          0.244663        0.009137\n",
      "3          0.239980        0.009283\n",
      "4          0.239980        0.009283\n",
      "..              ...             ...\n",
      "91         0.207240        0.014982\n",
      "92         0.207240        0.014982\n",
      "93         0.234867        0.009026\n",
      "94         0.234867        0.009026\n",
      "95         0.234867        0.009026\n",
      "\n",
      "[96 rows x 2 columns]\n",
      "\n",
      "SMOTE config: {'smote': None, 'under_sampler': RandomUnderSampler(random_state=42, sampling_strategy=0.5)}, CV: 3\n",
      "Best parameters: {'classifier__class_weight': None, 'classifier__max_depth': 7, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}\n",
      "Best cross-validation score: 0.2517956607930529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.83      0.89      3624\n",
      "           1       0.15      0.49      0.23       231\n",
      "\n",
      "    accuracy                           0.81      3855\n",
      "   macro avg       0.56      0.66      0.56      3855\n",
      "weighted avg       0.91      0.81      0.85      3855\n",
      "\n",
      "      0    1\n",
      "0  2992  632\n",
      "1   118  113\n",
      "\n",
      "Detailed cross-validation scores:\n",
      "    mean_test_score  std_test_score\n",
      "0          0.247406        0.022388\n",
      "1          0.247406        0.022388\n",
      "2          0.247953        0.023162\n",
      "3          0.245667        0.019302\n",
      "4          0.245667        0.019302\n",
      "..              ...             ...\n",
      "91         0.219639        0.017172\n",
      "92         0.219639        0.017172\n",
      "93         0.236135        0.014691\n",
      "94         0.236135        0.014691\n",
      "95         0.236135        0.014691\n",
      "\n",
      "[96 rows x 2 columns]\n",
      "\n",
      "SMOTE config: {'smote': None, 'under_sampler': RandomUnderSampler(random_state=42, sampling_strategy=0.5)}, CV: 4\n",
      "Best parameters: {'classifier__class_weight': None, 'classifier__max_depth': 5, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}\n",
      "Best cross-validation score: 0.24972964767920372\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.85      0.90      3624\n",
      "           1       0.16      0.45      0.23       231\n",
      "\n",
      "    accuracy                           0.82      3855\n",
      "   macro avg       0.56      0.65      0.57      3855\n",
      "weighted avg       0.91      0.82      0.86      3855\n",
      "\n",
      "      0    1\n",
      "0  3065  559\n",
      "1   127  104\n",
      "\n",
      "Detailed cross-validation scores:\n",
      "    mean_test_score  std_test_score\n",
      "0          0.248993        0.015872\n",
      "1          0.249203        0.016047\n",
      "2          0.249730        0.015583\n",
      "3          0.245971        0.016667\n",
      "4          0.245971        0.016667\n",
      "..              ...             ...\n",
      "91         0.232731        0.005851\n",
      "92         0.232731        0.005851\n",
      "93         0.230480        0.008632\n",
      "94         0.230480        0.008632\n",
      "95         0.230480        0.008632\n",
      "\n",
      "[96 rows x 2 columns]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE config: {'smote': None, 'under_sampler': RandomUnderSampler(random_state=42, sampling_strategy=0.5)}, CV: 5\n",
      "Best parameters: {'classifier__class_weight': None, 'classifier__max_depth': 5, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}\n",
      "Best cross-validation score: 0.25421406465216234\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.85      0.90      3624\n",
      "           1       0.16      0.44      0.23       231\n",
      "\n",
      "    accuracy                           0.82      3855\n",
      "   macro avg       0.56      0.64      0.57      3855\n",
      "weighted avg       0.91      0.82      0.86      3855\n",
      "\n",
      "      0    1\n",
      "0  3071  553\n",
      "1   129  102\n",
      "\n",
      "Detailed cross-validation scores:\n",
      "    mean_test_score  std_test_score\n",
      "0          0.250706        0.009131\n",
      "1          0.251802        0.007526\n",
      "2          0.253192        0.008173\n",
      "3          0.250024        0.005082\n",
      "4          0.250024        0.005082\n",
      "..              ...             ...\n",
      "91         0.222765        0.012030\n",
      "92         0.222765        0.012030\n",
      "93         0.234145        0.003655\n",
      "94         0.234145        0.003655\n",
      "95         0.234145        0.003655\n",
      "\n",
      "[96 rows x 2 columns]\n",
      "\n",
      "SMOTE config: {'smote': None, 'under_sampler': RandomUnderSampler(random_state=42, sampling_strategy=0.4)}, CV: 3\n",
      "Best parameters: {'classifier__class_weight': None, 'classifier__max_depth': 7, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}\n",
      "Best cross-validation score: 0.26053306814930605\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.83      0.89      3624\n",
      "           1       0.16      0.51      0.24       231\n",
      "\n",
      "    accuracy                           0.81      3855\n",
      "   macro avg       0.56      0.67      0.57      3855\n",
      "weighted avg       0.92      0.81      0.85      3855\n",
      "\n",
      "      0    1\n",
      "0  3016  608\n",
      "1   114  117\n",
      "\n",
      "Detailed cross-validation scores:\n",
      "    mean_test_score  std_test_score\n",
      "0          0.251199        0.012609\n",
      "1          0.252503        0.011411\n",
      "2          0.254624        0.014393\n",
      "3          0.251781        0.011966\n",
      "4          0.251781        0.011966\n",
      "..              ...             ...\n",
      "91         0.233661        0.011317\n",
      "92         0.233661        0.011317\n",
      "93         0.220571        0.014753\n",
      "94         0.220571        0.014753\n",
      "95         0.220571        0.014753\n",
      "\n",
      "[96 rows x 2 columns]\n",
      "\n",
      "SMOTE config: {'smote': None, 'under_sampler': RandomUnderSampler(random_state=42, sampling_strategy=0.4)}, CV: 4\n",
      "Best parameters: {'classifier__class_weight': None, 'classifier__max_depth': 5, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}\n",
      "Best cross-validation score: 0.2658355297803817\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.84      0.90      3624\n",
      "           1       0.16      0.49      0.24       231\n",
      "\n",
      "    accuracy                           0.82      3855\n",
      "   macro avg       0.56      0.67      0.57      3855\n",
      "weighted avg       0.91      0.82      0.86      3855\n",
      "\n",
      "      0    1\n",
      "0  3036  588\n",
      "1   117  114\n",
      "\n",
      "Detailed cross-validation scores:\n",
      "    mean_test_score  std_test_score\n",
      "0          0.262558        0.012714\n",
      "1          0.263868        0.012364\n",
      "2          0.264715        0.011419\n",
      "3          0.260865        0.009654\n",
      "4          0.260865        0.009654\n",
      "..              ...             ...\n",
      "91         0.230797        0.011955\n",
      "92         0.230797        0.011955\n",
      "93         0.229908        0.003145\n",
      "94         0.229908        0.003145\n",
      "95         0.229908        0.003145\n",
      "\n",
      "[96 rows x 2 columns]\n",
      "\n",
      "SMOTE config: {'smote': None, 'under_sampler': RandomUnderSampler(random_state=42, sampling_strategy=0.4)}, CV: 5\n",
      "Best parameters: {'classifier__class_weight': None, 'classifier__max_depth': 10, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}\n",
      "Best cross-validation score: 0.2618114129963535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.83      0.89      3624\n",
      "           1       0.15      0.49      0.23       231\n",
      "\n",
      "    accuracy                           0.80      3855\n",
      "   macro avg       0.56      0.66      0.56      3855\n",
      "weighted avg       0.91      0.80      0.85      3855\n",
      "\n",
      "      0    1\n",
      "0  2990  634\n",
      "1   118  113\n",
      "\n",
      "Detailed cross-validation scores:\n",
      "    mean_test_score  std_test_score\n",
      "0          0.255595        0.011083\n",
      "1          0.255595        0.011083\n",
      "2          0.256489        0.010358\n",
      "3          0.251625        0.013165\n",
      "4          0.251625        0.013165\n",
      "..              ...             ...\n",
      "91         0.222368        0.013030\n",
      "92         0.222368        0.013030\n",
      "93         0.230442        0.009955\n",
      "94         0.230442        0.009955\n",
      "95         0.230442        0.009955\n",
      "\n",
      "[96 rows x 2 columns]\n",
      "\n",
      "SMOTE config: {'smote': None, 'under_sampler': RandomUnderSampler(random_state=42, sampling_strategy=0.3)}, CV: 3\n",
      "Best parameters: {'classifier__class_weight': None, 'classifier__max_depth': 7, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}\n",
      "Best cross-validation score: 0.260951415231247\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.89      0.92      3624\n",
      "           1       0.19      0.39      0.25       231\n",
      "\n",
      "    accuracy                           0.86      3855\n",
      "   macro avg       0.57      0.64      0.59      3855\n",
      "weighted avg       0.91      0.86      0.88      3855\n",
      "\n",
      "      0    1\n",
      "0  3239  385\n",
      "1   142   89\n",
      "\n",
      "Detailed cross-validation scores:\n",
      "    mean_test_score  std_test_score\n",
      "0          0.169522        0.080051\n",
      "1          0.169640        0.080174\n",
      "2          0.171938        0.080364\n",
      "3          0.173193        0.075797\n",
      "4          0.173193        0.075797\n",
      "..              ...             ...\n",
      "91         0.227815        0.001058\n",
      "92         0.227815        0.001058\n",
      "93         0.237550        0.003002\n",
      "94         0.237550        0.003002\n",
      "95         0.237550        0.003002\n",
      "\n",
      "[96 rows x 2 columns]\n",
      "\n",
      "SMOTE config: {'smote': None, 'under_sampler': RandomUnderSampler(random_state=42, sampling_strategy=0.3)}, CV: 4\n",
      "Best parameters: {'classifier__class_weight': None, 'classifier__max_depth': 7, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}\n",
      "Best cross-validation score: 0.2620825881308369\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.89      0.92      3624\n",
      "           1       0.19      0.42      0.26       231\n",
      "\n",
      "    accuracy                           0.86      3855\n",
      "   macro avg       0.57      0.65      0.59      3855\n",
      "weighted avg       0.91      0.86      0.88      3855\n",
      "\n",
      "      0    1\n",
      "0  3215  409\n",
      "1   135   96\n",
      "\n",
      "Detailed cross-validation scores:\n",
      "    mean_test_score  std_test_score\n",
      "0          0.197101        0.058771\n",
      "1          0.197767        0.058493\n",
      "2          0.198748        0.057263\n",
      "3          0.193562        0.060307\n",
      "4          0.193562        0.060307\n",
      "..              ...             ...\n",
      "91         0.223627        0.015477\n",
      "92         0.223627        0.015477\n",
      "93         0.237234        0.007637\n",
      "94         0.237234        0.007637\n",
      "95         0.237234        0.007637\n",
      "\n",
      "[96 rows x 2 columns]\n",
      "\n",
      "SMOTE config: {'smote': None, 'under_sampler': RandomUnderSampler(random_state=42, sampling_strategy=0.3)}, CV: 5\n",
      "Best parameters: {'classifier__class_weight': None, 'classifier__max_depth': 5, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}\n",
      "Best cross-validation score: 0.27007248646719023\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.86      0.91      3624\n",
      "           1       0.17      0.45      0.24       231\n",
      "\n",
      "    accuracy                           0.83      3855\n",
      "   macro avg       0.56      0.65      0.57      3855\n",
      "weighted avg       0.91      0.83      0.87      3855\n",
      "\n",
      "      0    1\n",
      "0  3100  524\n",
      "1   126  105\n",
      "\n",
      "Detailed cross-validation scores:\n",
      "    mean_test_score  std_test_score\n",
      "0          0.264383        0.012905\n",
      "1          0.264693        0.012837\n",
      "2          0.266441        0.013077\n",
      "3          0.266827        0.011660\n",
      "4          0.266827        0.011660\n",
      "..              ...             ...\n",
      "91         0.221056        0.011365\n",
      "92         0.221056        0.011365\n",
      "93         0.234837        0.010536\n",
      "94         0.234837        0.010536\n",
      "95         0.234837        0.010536\n",
      "\n",
      "[96 rows x 2 columns]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE config: {'smote': None, 'under_sampler': RandomUnderSampler(random_state=42, sampling_strategy=0.2)}, CV: 3\n",
      "Best parameters: {'classifier__class_weight': 'balanced', 'classifier__max_depth': 10, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}\n",
      "Best cross-validation score: 0.23672661963922148\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.65      0.79      3624\n",
      "           1       0.14      0.86      0.23       231\n",
      "\n",
      "    accuracy                           0.66      3855\n",
      "   macro avg       0.56      0.75      0.51      3855\n",
      "weighted avg       0.94      0.66      0.75      3855\n",
      "\n",
      "      0     1\n",
      "0  2365  1259\n",
      "1    33   198\n",
      "\n",
      "Detailed cross-validation scores:\n",
      "    mean_test_score  std_test_score\n",
      "0          0.119767        0.061678\n",
      "1          0.120173        0.061337\n",
      "2          0.120406        0.061269\n",
      "3          0.114739        0.066723\n",
      "4          0.114739        0.066723\n",
      "..              ...             ...\n",
      "91         0.223528        0.013537\n",
      "92         0.223528        0.013537\n",
      "93         0.229931        0.009088\n",
      "94         0.229931        0.009088\n",
      "95         0.229931        0.009088\n",
      "\n",
      "[96 rows x 2 columns]\n",
      "\n",
      "SMOTE config: {'smote': None, 'under_sampler': RandomUnderSampler(random_state=42, sampling_strategy=0.2)}, CV: 4\n",
      "Best parameters: {'classifier__class_weight': 'balanced', 'classifier__max_depth': 15, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}\n",
      "Best cross-validation score: 0.23924693852992135\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.71      0.82      3624\n",
      "           1       0.14      0.71      0.23       231\n",
      "\n",
      "    accuracy                           0.71      3855\n",
      "   macro avg       0.56      0.71      0.53      3855\n",
      "weighted avg       0.92      0.71      0.79      3855\n",
      "\n",
      "      0     1\n",
      "0  2585  1039\n",
      "1    66   165\n",
      "\n",
      "Detailed cross-validation scores:\n",
      "    mean_test_score  std_test_score\n",
      "0          0.116306        0.036515\n",
      "1          0.117027        0.035983\n",
      "2          0.117753        0.035562\n",
      "3          0.114219        0.041582\n",
      "4          0.114219        0.041582\n",
      "..              ...             ...\n",
      "91         0.230679        0.016722\n",
      "92         0.230679        0.016722\n",
      "93         0.231946        0.010181\n",
      "94         0.231946        0.010181\n",
      "95         0.231946        0.010181\n",
      "\n",
      "[96 rows x 2 columns]\n",
      "\n",
      "SMOTE config: {'smote': None, 'under_sampler': RandomUnderSampler(random_state=42, sampling_strategy=0.2)}, CV: 5\n",
      "Best parameters: {'classifier__class_weight': None, 'classifier__max_depth': 15, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}\n",
      "Best cross-validation score: 0.24815633276438173\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.95      3624\n",
      "           1       0.18      0.20      0.19       231\n",
      "\n",
      "    accuracy                           0.90      3855\n",
      "   macro avg       0.57      0.57      0.57      3855\n",
      "weighted avg       0.90      0.90      0.90      3855\n",
      "\n",
      "      0    1\n",
      "0  3413  211\n",
      "1   184   47\n",
      "\n",
      "Detailed cross-validation scores:\n",
      "    mean_test_score  std_test_score\n",
      "0          0.070665        0.063445\n",
      "1          0.070771        0.063393\n",
      "2          0.070909        0.063320\n",
      "3          0.070476        0.062934\n",
      "4          0.070476        0.062934\n",
      "..              ...             ...\n",
      "91         0.231859        0.008972\n",
      "92         0.231859        0.008972\n",
      "93         0.234111        0.008976\n",
      "94         0.234111        0.008976\n",
      "95         0.234111        0.008976\n",
      "\n",
      "[96 rows x 2 columns]\n",
      "\n",
      "SMOTE config: {'smote': SMOTE(random_state=42, sampling_strategy=1.0), 'under_sampler': RandomUnderSampler(random_state=42, sampling_strategy=0.8)}, CV: 3\n",
      "Best parameters: {'classifier__class_weight': None, 'classifier__max_depth': 10, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}\n",
      "Best cross-validation score: 0.23453483334178085\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.66      0.79      3624\n",
      "           1       0.12      0.74      0.21       231\n",
      "\n",
      "    accuracy                           0.67      3855\n",
      "   macro avg       0.55      0.70      0.50      3855\n",
      "weighted avg       0.93      0.67      0.76      3855\n",
      "\n",
      "      0     1\n",
      "0  2409  1215\n",
      "1    59   172\n",
      "\n",
      "Detailed cross-validation scores:\n",
      "    mean_test_score  std_test_score\n",
      "0          0.218353        0.003735\n",
      "1          0.218353        0.003735\n",
      "2          0.219527        0.004823\n",
      "3          0.217794        0.004112\n",
      "4          0.217794        0.004112\n",
      "..              ...             ...\n",
      "91         0.229434        0.002570\n",
      "92         0.229434        0.002570\n",
      "93         0.227236        0.012767\n",
      "94         0.227236        0.012767\n",
      "95         0.227236        0.012767\n",
      "\n",
      "[96 rows x 2 columns]\n",
      "\n",
      "SMOTE config: {'smote': SMOTE(random_state=42, sampling_strategy=1.0), 'under_sampler': RandomUnderSampler(random_state=42, sampling_strategy=0.8)}, CV: 4\n",
      "Best parameters: {'classifier__class_weight': None, 'classifier__max_depth': 10, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}\n",
      "Best cross-validation score: 0.2356586306093276\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.66      0.79      3624\n",
      "           1       0.12      0.74      0.21       231\n",
      "\n",
      "    accuracy                           0.67      3855\n",
      "   macro avg       0.55      0.70      0.50      3855\n",
      "weighted avg       0.93      0.67      0.76      3855\n",
      "\n",
      "      0     1\n",
      "0  2409  1215\n",
      "1    59   172\n",
      "\n",
      "Detailed cross-validation scores:\n",
      "    mean_test_score  std_test_score\n",
      "0          0.223589        0.007235\n",
      "1          0.223589        0.007235\n",
      "2          0.222861        0.007714\n",
      "3          0.221414        0.008520\n",
      "4          0.221414        0.008520\n",
      "..              ...             ...\n",
      "91         0.222347        0.009018\n",
      "92         0.222347        0.009018\n",
      "93         0.234447        0.010641\n",
      "94         0.234447        0.010641\n",
      "95         0.234447        0.010641\n",
      "\n",
      "[96 rows x 2 columns]\n",
      "\n",
      "SMOTE config: {'smote': SMOTE(random_state=42, sampling_strategy=1.0), 'under_sampler': RandomUnderSampler(random_state=42, sampling_strategy=0.8)}, CV: 5\n",
      "Best parameters: {'classifier__class_weight': None, 'classifier__max_depth': 10, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}\n",
      "Best cross-validation score: 0.24081111567806812\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.66      0.79      3624\n",
      "           1       0.12      0.74      0.21       231\n",
      "\n",
      "    accuracy                           0.67      3855\n",
      "   macro avg       0.55      0.70      0.50      3855\n",
      "weighted avg       0.93      0.67      0.76      3855\n",
      "\n",
      "      0     1\n",
      "0  2409  1215\n",
      "1    59   172\n",
      "\n",
      "Detailed cross-validation scores:\n",
      "    mean_test_score  std_test_score\n",
      "0          0.223325        0.005255\n",
      "1          0.223325        0.005255\n",
      "2          0.223401        0.004799\n",
      "3          0.220464        0.006337\n",
      "4          0.220464        0.006337\n",
      "..              ...             ...\n",
      "91         0.224014        0.011344\n",
      "92         0.224014        0.011344\n",
      "93         0.234067        0.007716\n",
      "94         0.234067        0.007716\n",
      "95         0.234067        0.007716\n",
      "\n",
      "[96 rows x 2 columns]\n",
      "\n",
      "\n",
      "Best overall result:\n",
      "SMOTE config: {'smote': None, 'under_sampler': RandomUnderSampler(random_state=42, sampling_strategy=0.3)}, CV: 5\n",
      "Best parameters: {'classifier__class_weight': None, 'classifier__max_depth': 5, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}\n",
      "Best cross-validation score: 0.27007248646719023\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.91</td>\n",
       "      <td>3624.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.17</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.24</td>\n",
       "      <td>231.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.56</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.57</td>\n",
       "      <td>3855.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.87</td>\n",
       "      <td>3855.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision  recall  f1-score  support\n",
       "0                  0.96    0.86      0.91  3624.00\n",
       "1                  0.17    0.45      0.24   231.00\n",
       "accuracy           0.83    0.83      0.83     0.83\n",
       "macro avg          0.56    0.65      0.57  3855.00\n",
       "weighted avg       0.91    0.83      0.87  3855.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0    1\n",
      "0  3100  524\n",
      "1   126  105\n",
      "\n",
      "Worst overall result:\n",
      "SMOTE config: {'smote': SMOTE(random_state=42, sampling_strategy=1.0), 'under_sampler': RandomUnderSampler(random_state=42, sampling_strategy=0.8)}, CV: 3\n",
      "Best parameters: {'classifier__class_weight': None, 'classifier__max_depth': 10, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}\n",
      "Best cross-validation score: 0.23453483334178085\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.79</td>\n",
       "      <td>3624.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.12</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.21</td>\n",
       "      <td>231.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.50</td>\n",
       "      <td>3855.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.93</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.76</td>\n",
       "      <td>3855.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision  recall  f1-score  support\n",
       "0                  0.98    0.66      0.79  3624.00\n",
       "1                  0.12    0.74      0.21   231.00\n",
       "accuracy           0.67    0.67      0.67     0.67\n",
       "macro avg          0.55    0.70      0.50  3855.00\n",
       "weighted avg       0.93    0.67      0.76  3855.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0     1\n",
      "0  2409  1215\n",
      "1    59   172\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "data = pd.read_csv('fraud_vihecles.csv')\n",
    "\n",
    "# Set X and y\n",
    "X = data.drop(columns=['FraudFound_P'])\n",
    "y = data['FraudFound_P']\n",
    "\n",
    "# Split the data with stratification on the target column\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, stratify=y, random_state=42)\n",
    "\n",
    "# List of columns to drop\n",
    "columns_to_drop = ['PolicyNumber'] #'WeekOfMonth', 'DayOfWeek', 'RepNumber', , 'Age'\n",
    "\n",
    "# Define the preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('drop_columns', 'drop', columns_to_drop),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), X_train.columns.difference(columns_to_drop))\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'classifier__max_depth': [5, 7, 10, 15],\n",
    "    'classifier__min_samples_split': [2, 3, 10],\n",
    "    'classifier__min_samples_leaf': [1, 2, 5, 10],\n",
    "    'classifier__class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "# SMOTE and under-sampling configurations based on the requirements\n",
    "smote_configs = [\n",
    "    # 1. Keep the original class proportion\n",
    "    {'smote': None, 'under_sampler': None},\n",
    "    \n",
    "    # 2. Keep the same fraud, downsample non-fraudulent rows by 40%\n",
    "    {'smote': None, 'under_sampler': RandomUnderSampler(sampling_strategy=0.6, random_state=42)},\n",
    "    \n",
    "    # 3. Keep the same fraud, downsample non-fraudulent rows by 50%\n",
    "    {'smote': None, 'under_sampler': RandomUnderSampler(sampling_strategy=0.5, random_state=42)},\n",
    "    \n",
    "    # 4. Keep the same fraud, downsample non-fraudulent rows by 60%\n",
    "    {'smote': None, 'under_sampler': RandomUnderSampler(sampling_strategy=0.4, random_state=42)},\n",
    "    \n",
    "    # 5. Keep the same fraud, downsample non-fraudulent rows by 70%\n",
    "    {'smote': None, 'under_sampler': RandomUnderSampler(sampling_strategy=0.3, random_state=42)},\n",
    "    \n",
    "    # 6. Keep the same fraud, downsample non-fraudulent rows by 80%\n",
    "    {'smote': None, 'under_sampler': RandomUnderSampler(sampling_strategy=0.2, random_state=42)},\n",
    "    \n",
    "    # 7. Increase fraud by 100%, downsample non-fraudulent rows by 80%\n",
    "    {'smote': SMOTE(sampling_strategy=1.0, random_state=42), 'under_sampler': RandomUnderSampler(sampling_strategy=0.8, random_state=42)}\n",
    "]\n",
    "\n",
    "# Define the F-beta scorer with beta=1.0 (F1 score)\n",
    "fbeta_scorer = make_scorer(fbeta_score, beta=1.0, pos_label=1)\n",
    "\n",
    "# Cross-validation strategies\n",
    "cv_strategies = [3, 4, 5]\n",
    "\n",
    "best_results = []\n",
    "\n",
    "# Loop through SMOTE configurations and CV strategies\n",
    "for smote_config in smote_configs:\n",
    "    for cv in cv_strategies:\n",
    "        pipeline = ImbPipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('under_sampler', smote_config['under_sampler']),\n",
    "            ('smote', smote_config['smote']),\n",
    "            ('classifier', DecisionTreeClassifier(random_state=42))\n",
    "        ])\n",
    "        \n",
    "        grid_search = GridSearchCV(pipeline, param_grid, cv=cv, scoring=fbeta_scorer, n_jobs=-1)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        \n",
    "        best_params = grid_search.best_params_\n",
    "        best_score = grid_search.best_score_\n",
    "        \n",
    "        y_pred = grid_search.predict(X_test)\n",
    "        report = classification_report(y_test, y_pred, output_dict=True)\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        \n",
    "        best_results.append({\n",
    "            'smote_config': smote_config,\n",
    "            'cv': cv,\n",
    "            'best_params': best_params,\n",
    "            'best_score': best_score,\n",
    "            'classification_report': report,\n",
    "            'confusion_matrix': cm\n",
    "        })\n",
    "        \n",
    "        print(f\"SMOTE config: {smote_config}, CV: {cv}\")\n",
    "        print(f\"Best parameters: {best_params}\")\n",
    "        print(f\"Best cross-validation score: {best_score}\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        print(pd.DataFrame(cm, index=grid_search.classes_, columns=grid_search.classes_))\n",
    "        \n",
    "        print(\"\\nDetailed cross-validation scores:\")\n",
    "        cv_results = pd.DataFrame(grid_search.cv_results_)\n",
    "        print(cv_results[['mean_test_score', 'std_test_score']])\n",
    "        print()\n",
    "\n",
    "# Find the best overall result\n",
    "best_result = max(best_results, key=lambda x: x['best_score'])\n",
    "\n",
    "print(\"\\nBest overall result:\")\n",
    "print(f\"SMOTE config: {best_result['smote_config']}, CV: {best_result['cv']}\")\n",
    "print(f\"Best parameters: {best_result['best_params']}\")\n",
    "print(f\"Best cross-validation score: {best_result['best_score']}\")\n",
    "display(pd.DataFrame(best_result['classification_report']).transpose().round(2))\n",
    "print(pd.DataFrame(best_result['confusion_matrix'], index=grid_search.classes_, columns=grid_search.classes_))\n",
    "\n",
    "\n",
    "# Find the worst overall result\n",
    "worst_result = min(best_results, key=lambda x: x['best_score'])\n",
    "\n",
    "print(\"\\nWorst overall result:\")\n",
    "print(f\"SMOTE config: {worst_result['smote_config']}, CV: {worst_result['cv']}\")\n",
    "print(f\"Best parameters: {worst_result['best_params']}\")\n",
    "print(f\"Best cross-validation score: {worst_result['best_score']}\")\n",
    "display(pd.DataFrame(worst_result['classification_report']).transpose().round(2))\n",
    "print(pd.DataFrame(worst_result['confusion_matrix'], index=grid_search.classes_, columns=grid_search.classes_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57de5f37",
   "metadata": {},
   "source": [
    "## 6. Modeling with Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210f6664",
   "metadata": {},
   "source": [
    "#### 6.1 Building a benchmark model to take a look what we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "749225bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-51 {color: black;}#sk-container-id-51 pre{padding: 0;}#sk-container-id-51 div.sk-toggleable {background-color: white;}#sk-container-id-51 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-51 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-51 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-51 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-51 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-51 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-51 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-51 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-51 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-51 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-51 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-51 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-51 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-51 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-51 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-51 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-51 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-51 div.sk-item {position: relative;z-index: 1;}#sk-container-id-51 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-51 div.sk-item::before, #sk-container-id-51 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-51 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-51 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-51 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-51 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-51 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-51 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-51 div.sk-label-container {text-align: center;}#sk-container-id-51 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-51 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-51\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=15, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-51\" type=\"checkbox\" checked><label for=\"sk-estimator-id-51\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=15, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=15, random_state=42)"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, let's instantiate the model\n",
    "rfc = RandomForestClassifier(random_state=42, max_depth = 15)\n",
    "\n",
    "# Let's fit the model\n",
    "rfc.fit(X_train_encoded, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "1b67d69e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0   1\n",
      "0  10873   0\n",
      "1    598  94\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97     10873\n",
      "           1       1.00      0.14      0.24       692\n",
      "\n",
      "    accuracy                           0.95     11565\n",
      "   macro avg       0.97      0.57      0.61     11565\n",
      "weighted avg       0.95      0.95      0.93     11565\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Running on train data\n",
    "cm = confusion_matrix(y_true=y_train,\n",
    "                      y_pred=rfc.predict(X_train_encoded))\n",
    "print(pd.DataFrame(cm,\n",
    "             index=rfc.classes_,\n",
    "             columns=rfc.classes_))\n",
    "\n",
    "print(classification_report(y_train, rfc.predict(X_train_encoded)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "8d9f988f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0  1\n",
      "0  3624  0\n",
      "1   230  1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      3624\n",
      "           1       1.00      0.00      0.01       231\n",
      "\n",
      "    accuracy                           0.94      3855\n",
      "   macro avg       0.97      0.50      0.49      3855\n",
      "weighted avg       0.94      0.94      0.91      3855\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Running on test data\n",
    "cm = confusion_matrix(y_true=y_test,\n",
    "                      y_pred=rfc.predict(X_test_encoded))\n",
    "print(pd.DataFrame(cm,\n",
    "             index=rfc.classes_,\n",
    "             columns=rfc.classes_))\n",
    "print(classification_report(y_test, rfc.predict(X_test_encoded)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76dee8c8",
   "metadata": {},
   "source": [
    "#### 6.2 Pipeline with gridsearch and finding the best hyperparameters and learning the metrics using OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "1a6b2e0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE config: {'smote': None, 'under_sampler': RandomUnderSampler(random_state=42, sampling_strategy=0.6)}, CV: 4\n",
      "Best parameters: {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2, 'classifier__n_estimators': 300}\n",
      "Best cross-validation score: 0.2645516831354884\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.87      0.91      3624\n",
      "           1       0.17      0.42      0.25       231\n",
      "\n",
      "    accuracy                           0.85      3855\n",
      "   macro avg       0.57      0.65      0.58      3855\n",
      "weighted avg       0.91      0.85      0.87      3855\n",
      "\n",
      "      0    1\n",
      "0  3163  461\n",
      "1   134   97\n",
      "SMOTE config: {'smote': None, 'under_sampler': RandomUnderSampler(random_state=42, sampling_strategy=0.6)}, CV: 5\n",
      "Best parameters: {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2, 'classifier__n_estimators': 200}\n",
      "Best cross-validation score: 0.2730487604249042\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.83      0.89      3624\n",
      "           1       0.17      0.56      0.26       231\n",
      "\n",
      "    accuracy                           0.81      3855\n",
      "   macro avg       0.57      0.69      0.58      3855\n",
      "weighted avg       0.92      0.81      0.85      3855\n",
      "\n",
      "      0    1\n",
      "0  2995  629\n",
      "1   102  129\n",
      "SMOTE config: {'smote': None, 'under_sampler': RandomUnderSampler(random_state=42, sampling_strategy=0.6)}, CV: 6\n",
      "Best parameters: {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5, 'classifier__n_estimators': 200}\n",
      "Best cross-validation score: 0.2787971820214174\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.87      0.91      3624\n",
      "           1       0.17      0.44      0.25       231\n",
      "\n",
      "    accuracy                           0.84      3855\n",
      "   macro avg       0.57      0.65      0.58      3855\n",
      "weighted avg       0.91      0.84      0.87      3855\n",
      "\n",
      "      0    1\n",
      "0  3141  483\n",
      "1   130  101\n",
      "SMOTE config: {'smote': None, 'under_sampler': RandomUnderSampler(random_state=42, sampling_strategy=0.5)}, CV: 4\n",
      "Best parameters: {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2, 'classifier__n_estimators': 300}\n",
      "Best cross-validation score: 0.2842783463380379\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.86      0.91      3624\n",
      "           1       0.18      0.46      0.26       231\n",
      "\n",
      "    accuracy                           0.84      3855\n",
      "   macro avg       0.57      0.66      0.58      3855\n",
      "weighted avg       0.91      0.84      0.87      3855\n",
      "\n",
      "      0    1\n",
      "0  3125  499\n",
      "1   124  107\n",
      "SMOTE config: {'smote': None, 'under_sampler': RandomUnderSampler(random_state=42, sampling_strategy=0.5)}, CV: 5\n",
      "Best parameters: {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2, 'classifier__n_estimators': 300}\n",
      "Best cross-validation score: 0.27341690136390606\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.83      0.89      3624\n",
      "           1       0.16      0.50      0.24       231\n",
      "\n",
      "    accuracy                           0.81      3855\n",
      "   macro avg       0.56      0.67      0.57      3855\n",
      "weighted avg       0.92      0.81      0.85      3855\n",
      "\n",
      "      0    1\n",
      "0  3013  611\n",
      "1   115  116\n",
      "SMOTE config: {'smote': None, 'under_sampler': RandomUnderSampler(random_state=42, sampling_strategy=0.5)}, CV: 6\n",
      "Best parameters: {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 3, 'classifier__min_samples_split': 2, 'classifier__n_estimators': 300}\n",
      "Best cross-validation score: 0.2797832638937833\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.87      0.91      3624\n",
      "           1       0.18      0.46      0.26       231\n",
      "\n",
      "    accuracy                           0.84      3855\n",
      "   macro avg       0.57      0.66      0.59      3855\n",
      "weighted avg       0.92      0.84      0.87      3855\n",
      "\n",
      "      0    1\n",
      "0  3140  484\n",
      "1   124  107\n",
      "SMOTE config: {'smote': None, 'under_sampler': RandomUnderSampler(random_state=42, sampling_strategy=0.4)}, CV: 4\n",
      "Best parameters: {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2, 'classifier__n_estimators': 300}\n",
      "Best cross-validation score: 0.27462339754009674\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.91      0.93      3624\n",
      "           1       0.22      0.39      0.28       231\n",
      "\n",
      "    accuracy                           0.88      3855\n",
      "   macro avg       0.59      0.65      0.61      3855\n",
      "weighted avg       0.91      0.88      0.90      3855\n",
      "\n",
      "      0    1\n",
      "0  3305  319\n",
      "1   141   90\n",
      "SMOTE config: {'smote': None, 'under_sampler': RandomUnderSampler(random_state=42, sampling_strategy=0.4)}, CV: 5\n",
      "Best parameters: {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2, 'classifier__n_estimators': 300}\n",
      "Best cross-validation score: 0.2802429551238114\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.90      0.93      3624\n",
      "           1       0.19      0.39      0.26       231\n",
      "\n",
      "    accuracy                           0.87      3855\n",
      "   macro avg       0.58      0.64      0.59      3855\n",
      "weighted avg       0.91      0.87      0.89      3855\n",
      "\n",
      "      0    1\n",
      "0  3256  368\n",
      "1   142   89\n",
      "SMOTE config: {'smote': None, 'under_sampler': RandomUnderSampler(random_state=42, sampling_strategy=0.4)}, CV: 6\n",
      "Best parameters: {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5, 'classifier__n_estimators': 300}\n",
      "Best cross-validation score: 0.287057303670815\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.90      0.93      3624\n",
      "           1       0.20      0.39      0.26       231\n",
      "\n",
      "    accuracy                           0.87      3855\n",
      "   macro avg       0.58      0.64      0.59      3855\n",
      "weighted avg       0.91      0.87      0.89      3855\n",
      "\n",
      "      0    1\n",
      "0  3263  361\n",
      "1   142   89\n",
      "SMOTE config: {'smote': None, 'under_sampler': RandomUnderSampler(random_state=42, sampling_strategy=0.3)}, CV: 4\n",
      "Best parameters: {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2, 'classifier__n_estimators': 300}\n",
      "Best cross-validation score: 0.2394871874787614\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      3624\n",
      "           1       0.28      0.20      0.24       231\n",
      "\n",
      "    accuracy                           0.92      3855\n",
      "   macro avg       0.62      0.59      0.60      3855\n",
      "weighted avg       0.91      0.92      0.92      3855\n",
      "\n",
      "      0    1\n",
      "0  3506  118\n",
      "1   184   47\n",
      "SMOTE config: {'smote': None, 'under_sampler': RandomUnderSampler(random_state=42, sampling_strategy=0.3)}, CV: 5\n",
      "Best parameters: {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2, 'classifier__n_estimators': 300}\n",
      "Best cross-validation score: 0.24028864396014155\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      3624\n",
      "           1       0.28      0.20      0.24       231\n",
      "\n",
      "    accuracy                           0.92      3855\n",
      "   macro avg       0.62      0.59      0.60      3855\n",
      "weighted avg       0.91      0.92      0.92      3855\n",
      "\n",
      "      0    1\n",
      "0  3506  118\n",
      "1   184   47\n",
      "SMOTE config: {'smote': None, 'under_sampler': RandomUnderSampler(random_state=42, sampling_strategy=0.3)}, CV: 6\n",
      "Best parameters: {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2, 'classifier__n_estimators': 200}\n",
      "Best cross-validation score: 0.23763425554887688\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.96      3624\n",
      "           1       0.27      0.21      0.24       231\n",
      "\n",
      "    accuracy                           0.92      3855\n",
      "   macro avg       0.61      0.59      0.60      3855\n",
      "weighted avg       0.91      0.92      0.91      3855\n",
      "\n",
      "      0    1\n",
      "0  3494  130\n",
      "1   182   49\n",
      "SMOTE config: {'smote': SMOTE(random_state=42, sampling_strategy=1.0), 'under_sampler': RandomUnderSampler(random_state=42, sampling_strategy=0.8)}, CV: 4\n",
      "Best parameters: {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2, 'classifier__n_estimators': 200}\n",
      "Best cross-validation score: 0.24086553615426043\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.64      0.77      3624\n",
      "           1       0.13      0.86      0.23       231\n",
      "\n",
      "    accuracy                           0.65      3855\n",
      "   macro avg       0.56      0.75      0.50      3855\n",
      "weighted avg       0.93      0.65      0.74      3855\n",
      "\n",
      "      0     1\n",
      "0  2305  1319\n",
      "1    33   198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE config: {'smote': SMOTE(random_state=42, sampling_strategy=1.0), 'under_sampler': RandomUnderSampler(random_state=42, sampling_strategy=0.8)}, CV: 5\n",
      "Best parameters: {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2, 'classifier__n_estimators': 200}\n",
      "Best cross-validation score: 0.2455922818247503\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.64      0.77      3624\n",
      "           1       0.13      0.86      0.23       231\n",
      "\n",
      "    accuracy                           0.65      3855\n",
      "   macro avg       0.56      0.75      0.50      3855\n",
      "weighted avg       0.93      0.65      0.74      3855\n",
      "\n",
      "      0     1\n",
      "0  2305  1319\n",
      "1    33   198\n",
      "SMOTE config: {'smote': SMOTE(random_state=42, sampling_strategy=1.0), 'under_sampler': RandomUnderSampler(random_state=42, sampling_strategy=0.8)}, CV: 6\n",
      "Best parameters: {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2, 'classifier__n_estimators': 300}\n",
      "Best cross-validation score: 0.2455267354454583\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.64      0.78      3624\n",
      "           1       0.13      0.86      0.23       231\n",
      "\n",
      "    accuracy                           0.65      3855\n",
      "   macro avg       0.56      0.75      0.50      3855\n",
      "weighted avg       0.93      0.65      0.74      3855\n",
      "\n",
      "      0     1\n",
      "0  2317  1307\n",
      "1    33   198\n",
      "\n",
      "Best overall result:\n",
      "SMOTE config: {'smote': None, 'under_sampler': RandomUnderSampler(random_state=42, sampling_strategy=0.4)}, CV: 6\n",
      "Best parameters: {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5, 'classifier__n_estimators': 300}\n",
      "Best cross-validation score: 0.287057303670815\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.93</td>\n",
       "      <td>3624.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.20</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.26</td>\n",
       "      <td>231.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.87</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.58</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.59</td>\n",
       "      <td>3855.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.89</td>\n",
       "      <td>3855.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision  recall  f1-score  support\n",
       "0                  0.96    0.90      0.93  3624.00\n",
       "1                  0.20    0.39      0.26   231.00\n",
       "accuracy           0.87    0.87      0.87     0.87\n",
       "macro avg          0.58    0.64      0.59  3855.00\n",
       "weighted avg       0.91    0.87      0.89  3855.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0    1\n",
      "0  3263  361\n",
      "1   142   89\n",
      "\n",
      "Worst overall result:\n",
      "SMOTE config: {'smote': None, 'under_sampler': RandomUnderSampler(random_state=42, sampling_strategy=0.3)}, CV: 6\n",
      "Worst parameters: {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2, 'classifier__n_estimators': 200}\n",
      "Worst cross-validation score: 0.23763425554887688\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>3624.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.27</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.24</td>\n",
       "      <td>231.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.61</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.60</td>\n",
       "      <td>3855.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.91</td>\n",
       "      <td>3855.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision  recall  f1-score  support\n",
       "0                  0.95    0.96      0.96  3624.00\n",
       "1                  0.27    0.21      0.24   231.00\n",
       "accuracy           0.92    0.92      0.92     0.92\n",
       "macro avg          0.61    0.59      0.60  3855.00\n",
       "weighted avg       0.91    0.92      0.91  3855.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0    1\n",
      "0  3494  130\n",
      "1   182   49\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "data = pd.read_csv('fraud_vihecles.csv')\n",
    "\n",
    "# Set X and y\n",
    "X = data.drop(columns=['FraudFound_P'])\n",
    "y = data['FraudFound_P']\n",
    "\n",
    "# Split the data with stratification on the target column\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, stratify=y, random_state=42)\n",
    "\n",
    "# List of columns to drop\n",
    "columns_to_drop = ['PolicyNumber'] #'WeekOfMonth', 'DayOfWeek', 'RepNumber', , 'Age'\n",
    "\n",
    "# Define the preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('drop_columns', 'drop', columns_to_drop),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), X_train.columns.difference(columns_to_drop))\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [200, 300],\n",
    "    'classifier__max_depth': [5, 7, 10, 15, 20],\n",
    "    'classifier__min_samples_split': [2, 5, 10],\n",
    "    'classifier__min_samples_leaf': [1, 3, 5, 7, 10],\n",
    "}\n",
    "\n",
    "# SMOTE and under-sampling configurations based on the requirements\n",
    "# SMOTE and under-sampling configurations based on the requirements\n",
    "smote_configs = [\n",
    "#     # 1. Keep the original class proportion\n",
    "#     {'smote': None, 'under_sampler': None}, commented out as not effective\n",
    "    \n",
    "    # 2. Keep the same fraud, downsample non-fraudulent rows by 40%\n",
    "    {'smote': None, 'under_sampler': RandomUnderSampler(sampling_strategy=0.6, random_state=42)},\n",
    "    \n",
    "    # 3. Keep the same fraud, downsample non-fraudulent rows by 50%\n",
    "    {'smote': None, 'under_sampler': RandomUnderSampler(sampling_strategy=0.5, random_state=42)},\n",
    "    \n",
    "    # 4. Keep the same fraud, downsample non-fraudulent rows by 60%\n",
    "    {'smote': None, 'under_sampler': RandomUnderSampler(sampling_strategy=0.4, random_state=42)},\n",
    "    \n",
    "    # 5. Keep the same fraud, downsample non-fraudulent rows by 70%\n",
    "    {'smote': None, 'under_sampler': RandomUnderSampler(sampling_strategy=0.3, random_state=42)},\n",
    "    \n",
    "    # 6. Increase fraud by 100%, downsample non-fraudulent rows by 80%\n",
    "    {'smote': SMOTE(sampling_strategy=1.0, random_state=42), 'under_sampler': RandomUnderSampler(sampling_strategy=0.8, random_state=42)}\n",
    "]\n",
    "\n",
    "# Cross-validation strategies\n",
    "cv_strategies = [4, 5, 6] # 3 removed as not effective\n",
    "\n",
    "best_results = []\n",
    "\n",
    "# Define the F-beta scorer with beta=1.0 (F1 score)\n",
    "fbeta_scorer = make_scorer(fbeta_score, beta=1.0, pos_label=1)\n",
    "\n",
    "# Loop through SMOTE configurations and CV strategies\n",
    "for smote_config in smote_configs:\n",
    "    for cv in cv_strategies:\n",
    "        pipeline = ImbPipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('under_sampler', smote_config['under_sampler']),\n",
    "            ('smote', smote_config['smote']),\n",
    "            ('classifier', RandomForestClassifier(random_state=42))\n",
    "        ])\n",
    "        \n",
    "        grid_search = GridSearchCV(pipeline, param_grid, cv=cv, scoring=fbeta_scorer, n_jobs=-1)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        \n",
    "        best_params = grid_search.best_params_\n",
    "        best_score = grid_search.best_score_\n",
    "        \n",
    "        y_pred = grid_search.predict(X_test)\n",
    "        report = classification_report(y_test, y_pred, output_dict=True)\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        \n",
    "        best_results.append({\n",
    "            'smote_config': smote_config,\n",
    "            'cv': cv,\n",
    "            'best_params': best_params,\n",
    "            'best_score': best_score,\n",
    "            'classification_report': report,\n",
    "            'confusion_matrix': cm\n",
    "        })\n",
    "        \n",
    "        print(f\"SMOTE config: {smote_config}, CV: {cv}\")\n",
    "        print(f\"Best parameters: {best_params}\")\n",
    "        print(f\"Best cross-validation score: {best_score}\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        print(pd.DataFrame(cm, index=grid_search.classes_, columns=grid_search.classes_))\n",
    "\n",
    "# Find the best overall result\n",
    "best_result = max(best_results, key=lambda x: x['best_score'])\n",
    "\n",
    "print(\"\\nBest overall result:\")\n",
    "print(f\"SMOTE config: {best_result['smote_config']}, CV: {best_result['cv']}\")\n",
    "print(f\"Best parameters: {best_result['best_params']}\")\n",
    "print(f\"Best cross-validation score: {best_result['best_score']}\")\n",
    "display(pd.DataFrame(best_result['classification_report']).transpose().round(2))\n",
    "print(pd.DataFrame(best_result['confusion_matrix'], index=grid_search.classes_, columns=grid_search.classes_))\n",
    "\n",
    "\n",
    "# Find the worst overall result\n",
    "worst_result = min(best_results, key=lambda x: x['best_score'])\n",
    "\n",
    "print(\"\\nWorst overall result:\")\n",
    "print(f\"SMOTE config: {worst_result['smote_config']}, CV: {worst_result['cv']}\")\n",
    "print(f\"Worst parameters: {worst_result['best_params']}\")\n",
    "print(f\"Worst cross-validation score: {worst_result['best_score']}\")\n",
    "display(pd.DataFrame(worst_result['classification_report']).transpose().round(2))\n",
    "print(pd.DataFrame(worst_result['confusion_matrix'], index=grid_search.classes_, columns=grid_search.classes_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae3aa77",
   "metadata": {},
   "source": [
    "## 7. Modeling with XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9338f828",
   "metadata": {},
   "source": [
    "#### 7.1 Building a benchmark model to take a look what we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "8303b6db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-46 {color: black;}#sk-container-id-46 pre{padding: 0;}#sk-container-id-46 div.sk-toggleable {background-color: white;}#sk-container-id-46 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-46 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-46 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-46 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-46 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-46 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-46 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-46 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-46 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-46 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-46 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-46 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-46 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-46 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-46 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-46 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-46 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-46 div.sk-item {position: relative;z-index: 1;}#sk-container-id-46 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-46 div.sk-item::before, #sk-container-id-46 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-46 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-46 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-46 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-46 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-46 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-46 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-46 div.sk-label-container {text-align: center;}#sk-container-id-46 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-46 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-46\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "              min_child_weight=4, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=100, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=42, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-46\" type=\"checkbox\" checked><label for=\"sk-estimator-id-46\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "              min_child_weight=4, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=100, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=42, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "              min_child_weight=4, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=100, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=42, ...)"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "xgb = XGBClassifier(\n",
    "    max_depth=3,\n",
    "    min_child_weight=4,\n",
    "    random_state=42,\n",
    "    n_estimators=100,\n",
    "    subsample=0.8\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "xgb.fit(X_train_encoded, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "52a8e9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0   1\n",
      "0  10867   6\n",
      "1    635  57\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97     10873\n",
      "           1       0.90      0.08      0.15       692\n",
      "\n",
      "    accuracy                           0.94     11565\n",
      "   macro avg       0.92      0.54      0.56     11565\n",
      "weighted avg       0.94      0.94      0.92     11565\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Running on train data\n",
    "cm = confusion_matrix(y_true=y_train,\n",
    "                      y_pred=xgb.predict(X_train_encoded))\n",
    "print(pd.DataFrame(cm,\n",
    "             index=xgb.classes_,\n",
    "             columns=xgb.classes_))\n",
    "\n",
    "print(classification_report(y_train, xgb.predict(X_train_encoded)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "e5f0105a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0   1\n",
      "0  3616   8\n",
      "1   221  10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      3624\n",
      "           1       0.56      0.04      0.08       231\n",
      "\n",
      "    accuracy                           0.94      3855\n",
      "   macro avg       0.75      0.52      0.52      3855\n",
      "weighted avg       0.92      0.94      0.92      3855\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Running on test data\n",
    "cm = confusion_matrix(y_true=y_test,\n",
    "                      y_pred=xgb.predict(X_test_encoded))\n",
    "print(pd.DataFrame(cm,\n",
    "             index=xgb.classes_,\n",
    "             columns=xgb.classes_))\n",
    "print(classification_report(y_test, xgb.predict(X_test_encoded)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211418a9",
   "metadata": {},
   "source": [
    "#### 7.2 Pipeline with gridsearch and finding the best hyperparameters and learning the metrics using OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "e583697d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE config: {'smote': None, 'under_sampler': None}, CV: 3\n",
      "Best parameters: {'classifier__learning_rate': 0.2, 'classifier__max_depth': 4, 'classifier__min_child_weight': 5, 'classifier__n_estimators': 200, 'classifier__scale_pos_weight': 13, 'classifier__subsample': 0.9}\n",
      "Best cross-validation recall score: 0.3094048857534198\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.87      0.92      3624\n",
      "           1       0.20      0.52      0.29       231\n",
      "\n",
      "    accuracy                           0.85      3855\n",
      "   macro avg       0.58      0.69      0.60      3855\n",
      "weighted avg       0.92      0.85      0.88      3855\n",
      "\n",
      "      0    1\n",
      "0  3151  473\n",
      "1   112  119\n",
      "SMOTE config: {'smote': None, 'under_sampler': None}, CV: 4\n",
      "Best parameters: {'classifier__learning_rate': 0.2, 'classifier__max_depth': 4, 'classifier__min_child_weight': 1, 'classifier__n_estimators': 200, 'classifier__scale_pos_weight': 10, 'classifier__subsample': 0.9}\n",
      "Best cross-validation recall score: 0.3060347464866321\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.88      0.92      3624\n",
      "           1       0.20      0.47      0.28       231\n",
      "\n",
      "    accuracy                           0.86      3855\n",
      "   macro avg       0.58      0.67      0.60      3855\n",
      "weighted avg       0.92      0.86      0.88      3855\n",
      "\n",
      "      0    1\n",
      "0  3196  428\n",
      "1   123  108\n",
      "SMOTE config: {'smote': None, 'under_sampler': None}, CV: 5\n",
      "Best parameters: {'classifier__learning_rate': 0.2, 'classifier__max_depth': 4, 'classifier__min_child_weight': 5, 'classifier__n_estimators': 200, 'classifier__scale_pos_weight': 13, 'classifier__subsample': 0.8}\n",
      "Best cross-validation recall score: 0.31616785621814025\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.88      0.92      3624\n",
      "           1       0.21      0.53      0.30       231\n",
      "\n",
      "    accuracy                           0.85      3855\n",
      "   macro avg       0.59      0.70      0.61      3855\n",
      "weighted avg       0.92      0.85      0.88      3855\n",
      "\n",
      "      0    1\n",
      "0  3171  453\n",
      "1   109  122\n",
      "SMOTE config: {'smote': None, 'under_sampler': RandomUnderSampler(random_state=42, sampling_strategy=0.6)}, CV: 3\n",
      "Best parameters: {'classifier__learning_rate': 0.3, 'classifier__max_depth': 8, 'classifier__min_child_weight': 1, 'classifier__n_estimators': 300, 'classifier__scale_pos_weight': 13, 'classifier__subsample': 0.9}\n",
      "Best cross-validation recall score: 0.2569719075118145\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.71      0.82      3624\n",
      "           1       0.14      0.77      0.24       231\n",
      "\n",
      "    accuracy                           0.71      3855\n",
      "   macro avg       0.56      0.74      0.53      3855\n",
      "weighted avg       0.93      0.71      0.79      3855\n",
      "\n",
      "      0     1\n",
      "0  2574  1050\n",
      "1    53   178\n",
      "SMOTE config: {'smote': None, 'under_sampler': RandomUnderSampler(random_state=42, sampling_strategy=0.6)}, CV: 4\n",
      "Best parameters: {'classifier__learning_rate': 0.3, 'classifier__max_depth': 6, 'classifier__min_child_weight': 1, 'classifier__n_estimators': 300, 'classifier__scale_pos_weight': 15, 'classifier__subsample': 0.9}\n",
      "Best cross-validation recall score: 0.25637835390171304\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.70      0.81      3624\n",
      "           1       0.14      0.76      0.23       231\n",
      "\n",
      "    accuracy                           0.70      3855\n",
      "   macro avg       0.56      0.73      0.52      3855\n",
      "weighted avg       0.93      0.70      0.78      3855\n",
      "\n",
      "      0     1\n",
      "0  2527  1097\n",
      "1    55   176\n",
      "SMOTE config: {'smote': None, 'under_sampler': RandomUnderSampler(random_state=42, sampling_strategy=0.6)}, CV: 5\n",
      "Best parameters: {'classifier__learning_rate': 0.2, 'classifier__max_depth': 8, 'classifier__min_child_weight': 1, 'classifier__n_estimators': 300, 'classifier__scale_pos_weight': 13, 'classifier__subsample': 0.9}\n",
      "Best cross-validation recall score: 0.26303566914390636\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.70      0.82      3624\n",
      "           1       0.14      0.76      0.24       231\n",
      "\n",
      "    accuracy                           0.70      3855\n",
      "   macro avg       0.56      0.73      0.53      3855\n",
      "weighted avg       0.93      0.70      0.78      3855\n",
      "\n",
      "      0     1\n",
      "0  2536  1088\n",
      "1    55   176\n",
      "SMOTE config: {'smote': None, 'under_sampler': RandomUnderSampler(random_state=42, sampling_strategy=0.5)}, CV: 3\n",
      "Best parameters: {'classifier__learning_rate': 0.2, 'classifier__max_depth': 12, 'classifier__min_child_weight': 1, 'classifier__n_estimators': 300, 'classifier__scale_pos_weight': 10, 'classifier__subsample': 0.8}\n",
      "Best cross-validation recall score: 0.2664020956911332\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.74      0.84      3624\n",
      "           1       0.15      0.71      0.24       231\n",
      "\n",
      "    accuracy                           0.74      3855\n",
      "   macro avg       0.56      0.72      0.54      3855\n",
      "weighted avg       0.93      0.74      0.81      3855\n",
      "\n",
      "      0    1\n",
      "0  2687  937\n",
      "1    68  163\n",
      "SMOTE config: {'smote': None, 'under_sampler': RandomUnderSampler(random_state=42, sampling_strategy=0.5)}, CV: 4\n",
      "Best parameters: {'classifier__learning_rate': 0.3, 'classifier__max_depth': 4, 'classifier__min_child_weight': 1, 'classifier__n_estimators': 300, 'classifier__scale_pos_weight': 13, 'classifier__subsample': 0.9}\n",
      "Best cross-validation recall score: 0.26281465678632066\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.71      0.83      3624\n",
      "           1       0.14      0.76      0.24       231\n",
      "\n",
      "    accuracy                           0.72      3855\n",
      "   macro avg       0.56      0.74      0.53      3855\n",
      "weighted avg       0.93      0.72      0.79      3855\n",
      "\n",
      "      0     1\n",
      "0  2585  1039\n",
      "1    56   175\n",
      "SMOTE config: {'smote': None, 'under_sampler': RandomUnderSampler(random_state=42, sampling_strategy=0.5)}, CV: 5\n",
      "Best parameters: {'classifier__learning_rate': 0.2, 'classifier__max_depth': 6, 'classifier__min_child_weight': 1, 'classifier__n_estimators': 200, 'classifier__scale_pos_weight': 10, 'classifier__subsample': 0.9}\n",
      "Best cross-validation recall score: 0.2717519920104171\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.72      0.83      3624\n",
      "           1       0.14      0.73      0.24       231\n",
      "\n",
      "    accuracy                           0.72      3855\n",
      "   macro avg       0.56      0.73      0.53      3855\n",
      "weighted avg       0.93      0.72      0.79      3855\n",
      "\n",
      "      0     1\n",
      "0  2604  1020\n",
      "1    62   169\n",
      "SMOTE config: {'smote': None, 'under_sampler': RandomUnderSampler(random_state=42, sampling_strategy=0.4)}, CV: 3\n",
      "Best parameters: {'classifier__learning_rate': 0.1, 'classifier__max_depth': 8, 'classifier__min_child_weight': 1, 'classifier__n_estimators': 200, 'classifier__scale_pos_weight': 10, 'classifier__subsample': 0.8}\n",
      "Best cross-validation recall score: 0.27886035849782675\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.73      0.84      3624\n",
      "           1       0.15      0.75      0.25       231\n",
      "\n",
      "    accuracy                           0.74      3855\n",
      "   macro avg       0.57      0.74      0.55      3855\n",
      "weighted avg       0.93      0.74      0.80      3855\n",
      "\n",
      "      0    1\n",
      "0  2663  961\n",
      "1    57  174\n",
      "SMOTE config: {'smote': None, 'under_sampler': RandomUnderSampler(random_state=42, sampling_strategy=0.4)}, CV: 4\n",
      "Best parameters: {'classifier__learning_rate': 0.2, 'classifier__max_depth': 6, 'classifier__min_child_weight': 2, 'classifier__n_estimators': 300, 'classifier__scale_pos_weight': 10, 'classifier__subsample': 0.8}\n",
      "Best cross-validation recall score: 0.27056596542358946\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.75      0.85      3624\n",
      "           1       0.15      0.70      0.25       231\n",
      "\n",
      "    accuracy                           0.75      3855\n",
      "   macro avg       0.56      0.73      0.55      3855\n",
      "weighted avg       0.93      0.75      0.81      3855\n",
      "\n",
      "      0    1\n",
      "0  2726  898\n",
      "1    69  162\n",
      "SMOTE config: {'smote': None, 'under_sampler': RandomUnderSampler(random_state=42, sampling_strategy=0.4)}, CV: 5\n",
      "Best parameters: {'classifier__learning_rate': 0.1, 'classifier__max_depth': 10, 'classifier__min_child_weight': 1, 'classifier__n_estimators': 300, 'classifier__scale_pos_weight': 10, 'classifier__subsample': 0.9}\n",
      "Best cross-validation recall score: 0.28562198468283256\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.76      0.86      3624\n",
      "           1       0.16      0.69      0.26       231\n",
      "\n",
      "    accuracy                           0.76      3855\n",
      "   macro avg       0.57      0.73      0.56      3855\n",
      "weighted avg       0.93      0.76      0.82      3855\n",
      "\n",
      "      0    1\n",
      "0  2761  863\n",
      "1    71  160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE config: {'smote': None, 'under_sampler': RandomUnderSampler(random_state=42, sampling_strategy=0.3)}, CV: 3\n",
      "Best parameters: {'classifier__learning_rate': 0.2, 'classifier__max_depth': 10, 'classifier__min_child_weight': 2, 'classifier__n_estimators': 200, 'classifier__scale_pos_weight': 10, 'classifier__subsample': 0.9}\n",
      "Best cross-validation recall score: 0.29475696642560356\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.82      0.89      3624\n",
      "           1       0.18      0.60      0.27       231\n",
      "\n",
      "    accuracy                           0.81      3855\n",
      "   macro avg       0.57      0.71      0.58      3855\n",
      "weighted avg       0.92      0.81      0.85      3855\n",
      "\n",
      "      0    1\n",
      "0  2973  651\n",
      "1    92  139\n",
      "SMOTE config: {'smote': None, 'under_sampler': RandomUnderSampler(random_state=42, sampling_strategy=0.3)}, CV: 4\n",
      "Best parameters: {'classifier__learning_rate': 0.1, 'classifier__max_depth': 6, 'classifier__min_child_weight': 2, 'classifier__n_estimators': 300, 'classifier__scale_pos_weight': 13, 'classifier__subsample': 0.9}\n",
      "Best cross-validation recall score: 0.28226191141319495\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.76      0.85      3624\n",
      "           1       0.16      0.73      0.26       231\n",
      "\n",
      "    accuracy                           0.75      3855\n",
      "   macro avg       0.57      0.74      0.56      3855\n",
      "weighted avg       0.93      0.75      0.82      3855\n",
      "\n",
      "      0    1\n",
      "0  2741  883\n",
      "1    63  168\n",
      "SMOTE config: {'smote': None, 'under_sampler': RandomUnderSampler(random_state=42, sampling_strategy=0.3)}, CV: 5\n",
      "Best parameters: {'classifier__learning_rate': 0.2, 'classifier__max_depth': 8, 'classifier__min_child_weight': 1, 'classifier__n_estimators': 300, 'classifier__scale_pos_weight': 13, 'classifier__subsample': 0.8}\n",
      "Best cross-validation recall score: 0.2978696222488715\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.82      0.89      3624\n",
      "           1       0.17      0.59      0.26       231\n",
      "\n",
      "    accuracy                           0.80      3855\n",
      "   macro avg       0.57      0.70      0.57      3855\n",
      "weighted avg       0.92      0.80      0.85      3855\n",
      "\n",
      "      0    1\n",
      "0  2957  667\n",
      "1    95  136\n",
      "SMOTE config: {'smote': SMOTE(random_state=42, sampling_strategy=1.0), 'under_sampler': RandomUnderSampler(random_state=42, sampling_strategy=0.8)}, CV: 3\n",
      "Best parameters: {'classifier__learning_rate': 0.3, 'classifier__max_depth': 6, 'classifier__min_child_weight': 1, 'classifier__n_estimators': 300, 'classifier__scale_pos_weight': 10, 'classifier__subsample': 0.9}\n",
      "Best cross-validation recall score: 0.24405441126729047\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.67      0.79      3624\n",
      "           1       0.13      0.80      0.23       231\n",
      "\n",
      "    accuracy                           0.67      3855\n",
      "   macro avg       0.56      0.73      0.51      3855\n",
      "weighted avg       0.93      0.67      0.76      3855\n",
      "\n",
      "      0     1\n",
      "0  2413  1211\n",
      "1    46   185\n",
      "SMOTE config: {'smote': SMOTE(random_state=42, sampling_strategy=1.0), 'under_sampler': RandomUnderSampler(random_state=42, sampling_strategy=0.8)}, CV: 4\n",
      "Best parameters: {'classifier__learning_rate': 0.3, 'classifier__max_depth': 10, 'classifier__min_child_weight': 1, 'classifier__n_estimators': 300, 'classifier__scale_pos_weight': 15, 'classifier__subsample': 0.9}\n",
      "Best cross-validation recall score: 0.24512955659489194\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.66      0.79      3624\n",
      "           1       0.13      0.81      0.23       231\n",
      "\n",
      "    accuracy                           0.67      3855\n",
      "   macro avg       0.56      0.74      0.51      3855\n",
      "weighted avg       0.93      0.67      0.76      3855\n",
      "\n",
      "      0     1\n",
      "0  2389  1235\n",
      "1    43   188\n",
      "SMOTE config: {'smote': SMOTE(random_state=42, sampling_strategy=1.0), 'under_sampler': RandomUnderSampler(random_state=42, sampling_strategy=0.8)}, CV: 5\n",
      "Best parameters: {'classifier__learning_rate': 0.2, 'classifier__max_depth': 10, 'classifier__min_child_weight': 1, 'classifier__n_estimators': 300, 'classifier__scale_pos_weight': 10, 'classifier__subsample': 0.9}\n",
      "Best cross-validation recall score: 0.24884971524465865\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.65      0.78      3624\n",
      "           1       0.13      0.83      0.23       231\n",
      "\n",
      "    accuracy                           0.66      3855\n",
      "   macro avg       0.56      0.74      0.51      3855\n",
      "weighted avg       0.93      0.66      0.75      3855\n",
      "\n",
      "      0     1\n",
      "0  2363  1261\n",
      "1    39   192\n",
      "\n",
      "Best overall result:\n",
      "SMOTE config: {'smote': None, 'under_sampler': None}, CV: 5\n",
      "Best parameters: {'classifier__learning_rate': 0.2, 'classifier__max_depth': 4, 'classifier__min_child_weight': 5, 'classifier__n_estimators': 200, 'classifier__scale_pos_weight': 13, 'classifier__subsample': 0.8}\n",
      "Best cross-validation score: 0.31616785621814025\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.92</td>\n",
       "      <td>3624.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.30</td>\n",
       "      <td>231.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.59</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.61</td>\n",
       "      <td>3855.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.92</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.88</td>\n",
       "      <td>3855.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision  recall  f1-score  support\n",
       "0                  0.97    0.88      0.92  3624.00\n",
       "1                  0.21    0.53      0.30   231.00\n",
       "accuracy           0.85    0.85      0.85     0.85\n",
       "macro avg          0.59    0.70      0.61  3855.00\n",
       "weighted avg       0.92    0.85      0.88  3855.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0    1\n",
      "0  3171  453\n",
      "1   109  122\n",
      "\n",
      "Worst overall result:\n",
      "SMOTE config: {'smote': SMOTE(random_state=42, sampling_strategy=1.0), 'under_sampler': RandomUnderSampler(random_state=42, sampling_strategy=0.8)}, CV: 3\n",
      "Worst parameters: {'classifier__learning_rate': 0.3, 'classifier__max_depth': 6, 'classifier__min_child_weight': 1, 'classifier__n_estimators': 300, 'classifier__scale_pos_weight': 10, 'classifier__subsample': 0.9}\n",
      "Worst cross-validation score: 0.24405441126729047\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.79</td>\n",
       "      <td>3624.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.13</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.23</td>\n",
       "      <td>231.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.56</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.51</td>\n",
       "      <td>3855.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.93</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.76</td>\n",
       "      <td>3855.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision  recall  f1-score  support\n",
       "0                  0.98    0.67      0.79  3624.00\n",
       "1                  0.13    0.80      0.23   231.00\n",
       "accuracy           0.67    0.67      0.67     0.67\n",
       "macro avg          0.56    0.73      0.51  3855.00\n",
       "weighted avg       0.93    0.67      0.76  3855.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0     1\n",
      "0  2413  1211\n",
      "1    46   185\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "data = pd.read_csv('fraud_vihecles.csv')\n",
    "\n",
    "# Set X and y\n",
    "X = data.drop(columns=['FraudFound_P'])\n",
    "y = data['FraudFound_P']\n",
    "\n",
    "# Split the data with stratification on the target column\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, stratify=y, random_state=42)\n",
    "\n",
    "# List of columns to drop\n",
    "columns_to_drop = ['PolicyNumber'] #'WeekOfMonth', 'DayOfWeek', 'RepNumber',  'Age'\n",
    "\n",
    "# Define the preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('drop_columns', 'drop', columns_to_drop),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), X_train.columns.difference(columns_to_drop))\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [200, 300],\n",
    "    'classifier__max_depth': [4, 6, 8, 10, 12],\n",
    "    'classifier__learning_rate': [0.1, 0.2, 0.3],\n",
    "    'classifier__min_child_weight': [1, 2, 5, 7],\n",
    "    'classifier__subsample': [0.8, 0.9],\n",
    "    'classifier__scale_pos_weight': [10, 13, 15, 17]\n",
    "}\n",
    "\n",
    "# SMOTE and under-sampling configurations based on the requirements\n",
    "smote_configs = [\n",
    "    # 1. Keep the original class proportion\n",
    "    {'smote': None, 'under_sampler': None}, # Uncommented since it may still be useful for comparison\n",
    "    \n",
    "    # 2. Keep the same fraud, downsample non-fraudulent rows by 40%\n",
    "    {'smote': None, 'under_sampler': RandomUnderSampler(sampling_strategy=0.6, random_state=42)},\n",
    "    \n",
    "    # 3. Keep the same fraud, downsample non-fraudulent rows by 50%\n",
    "    {'smote': None, 'under_sampler': RandomUnderSampler(sampling_strategy=0.5, random_state=42)},\n",
    "    \n",
    "    # 4. Keep the same fraud, downsample non-fraudulent rows by 60%\n",
    "    {'smote': None, 'under_sampler': RandomUnderSampler(sampling_strategy=0.4, random_state=42)},\n",
    "    \n",
    "    # 5. Keep the same fraud, downsample non-fraudulent rows by 70%\n",
    "    {'smote': None, 'under_sampler': RandomUnderSampler(sampling_strategy=0.3, random_state=42)},\n",
    "    \n",
    "    # 6. Increase fraud by 100%, downsample non-fraudulent rows by 80%\n",
    "    {'smote': SMOTE(sampling_strategy=1.0, random_state=42), 'under_sampler': RandomUnderSampler(sampling_strategy=0.8, random_state=42)}\n",
    "]\n",
    "\n",
    "# Cross-validation strategies\n",
    "cv_strategies = [3, 4, 5]\n",
    "\n",
    "best_results = []\n",
    "\n",
    "# Define the F-beta scorer with beta=1.0 (F1 score)\n",
    "fbeta_scorer = make_scorer(fbeta_score, beta=1.0, pos_label=1)\n",
    "\n",
    "# Loop through SMOTE configurations and CV strategies\n",
    "for smote_config in smote_configs:\n",
    "    for cv in cv_strategies:\n",
    "        pipeline = ImbPipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('under_sampler', smote_config['under_sampler']),\n",
    "            ('smote', smote_config['smote']),\n",
    "            ('classifier', XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss'))\n",
    "        ])\n",
    "        \n",
    "        grid_search = GridSearchCV(pipeline, param_grid, cv=cv, scoring=fbeta_scorer, n_jobs=-1)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        \n",
    "        best_params = grid_search.best_params_\n",
    "        best_score = grid_search.best_score_\n",
    "        \n",
    "        y_pred = grid_search.predict(X_test)\n",
    "        report = classification_report(y_test, y_pred, output_dict=True)\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        \n",
    "        best_results.append({\n",
    "            'smote_config': smote_config,\n",
    "            'cv': cv,\n",
    "            'best_params': best_params,\n",
    "            'best_score': best_score,\n",
    "            'classification_report': report,\n",
    "            'confusion_matrix': cm\n",
    "        })\n",
    "        \n",
    "        print(f\"SMOTE config: {smote_config}, CV: {cv}\")\n",
    "        print(f\"Best parameters: {best_params}\")\n",
    "        print(f\"Best cross-validation recall score: {best_score}\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        print(pd.DataFrame(cm, index=grid_search.classes_, columns=grid_search.classes_))\n",
    "\n",
    "# Find the best overall result\n",
    "best_result = max(best_results, key=lambda x: x['best_score'])\n",
    "\n",
    "print(\"\\nBest overall result:\")\n",
    "print(f\"SMOTE config: {best_result['smote_config']}, CV: {best_result['cv']}\")\n",
    "print(f\"Best parameters: {best_result['best_params']}\")\n",
    "print(f\"Best cross-validation score: {best_result['best_score']}\")\n",
    "display(pd.DataFrame(best_result['classification_report']).transpose().round(2))\n",
    "print(pd.DataFrame(best_result['confusion_matrix'], index=grid_search.classes_, columns=grid_search.classes_))\n",
    "\n",
    "\n",
    "# Find the worst overall result\n",
    "worst_result = min(best_results, key=lambda x: x['best_score'])\n",
    "\n",
    "print(\"\\nWorst overall result:\")\n",
    "print(f\"SMOTE config: {worst_result['smote_config']}, CV: {worst_result['cv']}\")\n",
    "print(f\"Worst parameters: {worst_result['best_params']}\")\n",
    "print(f\"Worst cross-validation score: {worst_result['best_score']}\")\n",
    "display(pd.DataFrame(worst_result['classification_report']).transpose().round(2))\n",
    "print(pd.DataFrame(worst_result['confusion_matrix'], index=grid_search.classes_, columns=grid_search.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a69684d",
   "metadata": {},
   "source": [
    "### An exmaple of getting some information that the model shouldn't get (we didn't remove InsuranceNumber feature, it seems like the model rely on it completely, which is something we don't want for our model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "344d6782",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99     11610\n",
      "           1       0.85      1.00      0.92       726\n",
      "\n",
      "    accuracy                           0.99     12336\n",
      "   macro avg       0.93      0.99      0.96     12336\n",
      "weighted avg       0.99      0.99      0.99     12336\n",
      "\n",
      "ROC-AUC: 0.9946167097329889\n",
      "Precision-Recall AUC: 0.926556991774383\n",
      "XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98      2887\n",
      "           1       0.65      0.83      0.73       197\n",
      "\n",
      "    accuracy                           0.96      3084\n",
      "   macro avg       0.82      0.90      0.85      3084\n",
      "weighted avg       0.97      0.96      0.96      3084\n",
      "\n",
      "ROC-AUC: 0.9008297303332461\n",
      "Precision-Recall AUC: 0.7457045213116231\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'fraud_vihecles.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Encode categorical variables using Label Encoding\n",
    "label_encoders = {}\n",
    "for column in data.select_dtypes(include=['object']).columns:\n",
    "    le = LabelEncoder()\n",
    "    data[column] = le.fit_transform(data[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X = data.drop('FraudFound_P', axis=1)\n",
    "y = data['FraudFound_P']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "xgb_model = XGBClassifier(scale_pos_weight=18, random_state=42, max_depth=6)\n",
    "\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_train_xgb = xgb_model.predict(X_train)\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"XGBoost:\")\n",
    "print(classification_report(y_train, y_train_xgb))\n",
    "\n",
    "# Evaluate using ROC-AUC and Precision-Recall Curve\n",
    "roc_auc_xgb = roc_auc_score(y_train, y_train_xgb)\n",
    "precision_xgb, recall_xgb, _ = precision_recall_curve(y_train, y_train_xgb)\n",
    "pr_auc_xgb = auc(recall_xgb, precision_xgb)\n",
    "print(f'ROC-AUC: {roc_auc_xgb}')\n",
    "print(f'Precision-Recall AUC: {pr_auc_xgb}')\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"XGBoost:\")\n",
    "print(classification_report(y_test, y_pred_xgb))\n",
    "\n",
    "# Evaluate using ROC-AUC and Precision-Recall Curve\n",
    "roc_auc_xgb = roc_auc_score(y_test, y_pred_xgb)\n",
    "precision_xgb, recall_xgb, _ = precision_recall_curve(y_test, y_pred_xgb)\n",
    "pr_auc_xgb = auc(recall_xgb, precision_xgb)\n",
    "print(f'ROC-AUC: {roc_auc_xgb}')\n",
    "print(f'Precision-Recall AUC: {pr_auc_xgb}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736e0e10",
   "metadata": {},
   "source": [
    "## 8. Modeling with CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "444b0484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.5686238\ttotal: 6.2ms\tremaining: 614ms\n",
      "1:\tlearn: 0.4860533\ttotal: 11.9ms\tremaining: 581ms\n",
      "2:\tlearn: 0.4231636\ttotal: 16.1ms\tremaining: 520ms\n",
      "3:\tlearn: 0.3750725\ttotal: 20.1ms\tremaining: 483ms\n",
      "4:\tlearn: 0.3290235\ttotal: 24.6ms\tremaining: 468ms\n",
      "5:\tlearn: 0.3013900\ttotal: 30.2ms\tremaining: 474ms\n",
      "6:\tlearn: 0.2823128\ttotal: 35.3ms\tremaining: 469ms\n",
      "7:\tlearn: 0.2677111\ttotal: 39.4ms\tremaining: 453ms\n",
      "8:\tlearn: 0.2454142\ttotal: 43.5ms\tremaining: 440ms\n",
      "9:\tlearn: 0.2365943\ttotal: 47.5ms\tremaining: 427ms\n",
      "10:\tlearn: 0.2260465\ttotal: 51.5ms\tremaining: 416ms\n",
      "11:\tlearn: 0.2178444\ttotal: 56.4ms\tremaining: 414ms\n",
      "12:\tlearn: 0.2147050\ttotal: 61.8ms\tremaining: 414ms\n",
      "13:\tlearn: 0.2075794\ttotal: 66.1ms\tremaining: 406ms\n",
      "14:\tlearn: 0.1998217\ttotal: 69.9ms\tremaining: 396ms\n",
      "15:\tlearn: 0.1982397\ttotal: 73.7ms\tremaining: 387ms\n",
      "16:\tlearn: 0.1935750\ttotal: 78ms\tremaining: 381ms\n",
      "17:\tlearn: 0.1927168\ttotal: 82.5ms\tremaining: 376ms\n",
      "18:\tlearn: 0.1893758\ttotal: 87ms\tremaining: 371ms\n",
      "19:\tlearn: 0.1881994\ttotal: 91.2ms\tremaining: 365ms\n",
      "20:\tlearn: 0.1865972\ttotal: 95.6ms\tremaining: 360ms\n",
      "21:\tlearn: 0.1856202\ttotal: 101ms\tremaining: 357ms\n",
      "22:\tlearn: 0.1836464\ttotal: 106ms\tremaining: 354ms\n",
      "23:\tlearn: 0.1830518\ttotal: 111ms\tremaining: 351ms\n",
      "24:\tlearn: 0.1819086\ttotal: 115ms\tremaining: 346ms\n",
      "25:\tlearn: 0.1808374\ttotal: 120ms\tremaining: 341ms\n",
      "26:\tlearn: 0.1797318\ttotal: 124ms\tremaining: 334ms\n",
      "27:\tlearn: 0.1796198\ttotal: 127ms\tremaining: 327ms\n",
      "28:\tlearn: 0.1790828\ttotal: 131ms\tremaining: 322ms\n",
      "29:\tlearn: 0.1785076\ttotal: 135ms\tremaining: 316ms\n",
      "30:\tlearn: 0.1782328\ttotal: 140ms\tremaining: 312ms\n",
      "31:\tlearn: 0.1777609\ttotal: 145ms\tremaining: 309ms\n",
      "32:\tlearn: 0.1775450\ttotal: 150ms\tremaining: 304ms\n",
      "33:\tlearn: 0.1771880\ttotal: 154ms\tremaining: 298ms\n",
      "34:\tlearn: 0.1769467\ttotal: 159ms\tremaining: 294ms\n",
      "35:\tlearn: 0.1768122\ttotal: 164ms\tremaining: 292ms\n",
      "36:\tlearn: 0.1764751\ttotal: 169ms\tremaining: 288ms\n",
      "37:\tlearn: 0.1762629\ttotal: 173ms\tremaining: 283ms\n",
      "38:\tlearn: 0.1755454\ttotal: 177ms\tremaining: 277ms\n",
      "39:\tlearn: 0.1754125\ttotal: 181ms\tremaining: 272ms\n",
      "40:\tlearn: 0.1752904\ttotal: 186ms\tremaining: 267ms\n",
      "41:\tlearn: 0.1750516\ttotal: 190ms\tremaining: 262ms\n",
      "42:\tlearn: 0.1743968\ttotal: 194ms\tremaining: 258ms\n",
      "43:\tlearn: 0.1739022\ttotal: 200ms\tremaining: 255ms\n",
      "44:\tlearn: 0.1737284\ttotal: 206ms\tremaining: 251ms\n",
      "45:\tlearn: 0.1736539\ttotal: 210ms\tremaining: 247ms\n",
      "46:\tlearn: 0.1734775\ttotal: 216ms\tremaining: 243ms\n",
      "47:\tlearn: 0.1731179\ttotal: 221ms\tremaining: 239ms\n",
      "48:\tlearn: 0.1727259\ttotal: 226ms\tremaining: 235ms\n",
      "49:\tlearn: 0.1724141\ttotal: 231ms\tremaining: 231ms\n",
      "50:\tlearn: 0.1719559\ttotal: 236ms\tremaining: 227ms\n",
      "51:\tlearn: 0.1717338\ttotal: 242ms\tremaining: 223ms\n",
      "52:\tlearn: 0.1713149\ttotal: 247ms\tremaining: 219ms\n",
      "53:\tlearn: 0.1711772\ttotal: 252ms\tremaining: 215ms\n",
      "54:\tlearn: 0.1709132\ttotal: 257ms\tremaining: 210ms\n",
      "55:\tlearn: 0.1707012\ttotal: 261ms\tremaining: 205ms\n",
      "56:\tlearn: 0.1701431\ttotal: 265ms\tremaining: 200ms\n",
      "57:\tlearn: 0.1697805\ttotal: 269ms\tremaining: 195ms\n",
      "58:\tlearn: 0.1695105\ttotal: 273ms\tremaining: 190ms\n",
      "59:\tlearn: 0.1691690\ttotal: 277ms\tremaining: 185ms\n",
      "60:\tlearn: 0.1690278\ttotal: 281ms\tremaining: 180ms\n",
      "61:\tlearn: 0.1684942\ttotal: 285ms\tremaining: 175ms\n",
      "62:\tlearn: 0.1682155\ttotal: 289ms\tremaining: 170ms\n",
      "63:\tlearn: 0.1680609\ttotal: 294ms\tremaining: 165ms\n",
      "64:\tlearn: 0.1677995\ttotal: 299ms\tremaining: 161ms\n",
      "65:\tlearn: 0.1675702\ttotal: 304ms\tremaining: 157ms\n",
      "66:\tlearn: 0.1671228\ttotal: 309ms\tremaining: 152ms\n",
      "67:\tlearn: 0.1667822\ttotal: 313ms\tremaining: 147ms\n",
      "68:\tlearn: 0.1667159\ttotal: 317ms\tremaining: 142ms\n",
      "69:\tlearn: 0.1664609\ttotal: 321ms\tremaining: 138ms\n",
      "70:\tlearn: 0.1662583\ttotal: 325ms\tremaining: 133ms\n",
      "71:\tlearn: 0.1659898\ttotal: 329ms\tremaining: 128ms\n",
      "72:\tlearn: 0.1657955\ttotal: 335ms\tremaining: 124ms\n",
      "73:\tlearn: 0.1653149\ttotal: 340ms\tremaining: 119ms\n",
      "74:\tlearn: 0.1651065\ttotal: 344ms\tremaining: 115ms\n",
      "75:\tlearn: 0.1648674\ttotal: 348ms\tremaining: 110ms\n",
      "76:\tlearn: 0.1647086\ttotal: 353ms\tremaining: 105ms\n",
      "77:\tlearn: 0.1644165\ttotal: 358ms\tremaining: 101ms\n",
      "78:\tlearn: 0.1642544\ttotal: 363ms\tremaining: 96.6ms\n",
      "79:\tlearn: 0.1642028\ttotal: 368ms\tremaining: 92ms\n",
      "80:\tlearn: 0.1640877\ttotal: 373ms\tremaining: 87.6ms\n",
      "81:\tlearn: 0.1640470\ttotal: 378ms\tremaining: 83ms\n",
      "82:\tlearn: 0.1638329\ttotal: 383ms\tremaining: 78.5ms\n",
      "83:\tlearn: 0.1635778\ttotal: 387ms\tremaining: 73.8ms\n",
      "84:\tlearn: 0.1634126\ttotal: 392ms\tremaining: 69.1ms\n",
      "85:\tlearn: 0.1626059\ttotal: 397ms\tremaining: 64.7ms\n",
      "86:\tlearn: 0.1624398\ttotal: 403ms\tremaining: 60.2ms\n",
      "87:\tlearn: 0.1623233\ttotal: 408ms\tremaining: 55.7ms\n",
      "88:\tlearn: 0.1621129\ttotal: 414ms\tremaining: 51.2ms\n",
      "89:\tlearn: 0.1620492\ttotal: 419ms\tremaining: 46.6ms\n",
      "90:\tlearn: 0.1617328\ttotal: 424ms\tremaining: 41.9ms\n",
      "91:\tlearn: 0.1616504\ttotal: 429ms\tremaining: 37.3ms\n",
      "92:\tlearn: 0.1615673\ttotal: 435ms\tremaining: 32.7ms\n",
      "93:\tlearn: 0.1611162\ttotal: 440ms\tremaining: 28.1ms\n",
      "94:\tlearn: 0.1609747\ttotal: 445ms\tremaining: 23.4ms\n",
      "95:\tlearn: 0.1609142\ttotal: 450ms\tremaining: 18.7ms\n",
      "96:\tlearn: 0.1608638\ttotal: 455ms\tremaining: 14.1ms\n",
      "97:\tlearn: 0.1605203\ttotal: 461ms\tremaining: 9.4ms\n",
      "98:\tlearn: 0.1603183\ttotal: 466ms\tremaining: 4.7ms\n",
      "99:\tlearn: 0.1601696\ttotal: 471ms\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x2820795b610>"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "catboost = CatBoostClassifier(\n",
    "    depth=5,\n",
    "    l2_leaf_reg=10,\n",
    "    random_seed=42,\n",
    "    iterations=100,\n",
    "    subsample=0.8,\n",
    "    learning_rate=0.1\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "catboost.fit(X_train_encoded, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "d3872ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0   1\n",
      "0  10873   0\n",
      "1    661  31\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97     10873\n",
      "           1       1.00      0.04      0.09       692\n",
      "\n",
      "    accuracy                           0.94     11565\n",
      "   macro avg       0.97      0.52      0.53     11565\n",
      "weighted avg       0.95      0.94      0.92     11565\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Running on train data\n",
    "cm = confusion_matrix(y_true=y_train,\n",
    "                      y_pred=catboost.predict(X_train_encoded))\n",
    "print(pd.DataFrame(cm,\n",
    "             index=catboost.classes_,\n",
    "             columns=catboost.classes_))\n",
    "\n",
    "print(classification_report(y_train, catboost.predict(X_train_encoded)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "33a006f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0  1\n",
      "0  3624  0\n",
      "1   225  6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      3624\n",
      "           1       1.00      0.03      0.05       231\n",
      "\n",
      "    accuracy                           0.94      3855\n",
      "   macro avg       0.97      0.51      0.51      3855\n",
      "weighted avg       0.95      0.94      0.91      3855\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Running on test data\n",
    "cm = confusion_matrix(y_true=y_test,\n",
    "                      y_pred=catboost.predict(X_test_encoded))\n",
    "print(pd.DataFrame(cm,\n",
    "             index=catboost.classes_,\n",
    "             columns=catboost.classes_))\n",
    "print(classification_report(y_test, catboost.predict(X_test_encoded)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "cc5d35c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE config: {'smote': None, 'under_sampler': None}, CV: 3\n",
      "Best parameters: {'classifier__depth': 4, 'classifier__iterations': 200, 'classifier__l2_leaf_reg': 2, 'classifier__learning_rate': 0.3, 'classifier__scale_pos_weight': 13, 'classifier__subsample': 0.8}\n",
      "Best cross-validation score: 0.2992001909029773\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.88      0.92      3624\n",
      "           1       0.21      0.52      0.30       231\n",
      "\n",
      "    accuracy                           0.85      3855\n",
      "   macro avg       0.59      0.70      0.61      3855\n",
      "weighted avg       0.92      0.85      0.88      3855\n",
      "\n",
      "      0    1\n",
      "0  3177  447\n",
      "1   112  119\n",
      "SMOTE config: {'smote': None, 'under_sampler': None}, CV: 4\n",
      "Best parameters: {'classifier__depth': 4, 'classifier__iterations': 200, 'classifier__l2_leaf_reg': 2, 'classifier__learning_rate': 0.3, 'classifier__scale_pos_weight': 8, 'classifier__subsample': 0.8}\n",
      "Best cross-validation score: 0.29013124685043723\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.92      0.94      3624\n",
      "           1       0.23      0.39      0.29       231\n",
      "\n",
      "    accuracy                           0.89      3855\n",
      "   macro avg       0.59      0.65      0.61      3855\n",
      "weighted avg       0.92      0.89      0.90      3855\n",
      "\n",
      "      0    1\n",
      "0  3323  301\n",
      "1   142   89\n",
      "SMOTE config: {'smote': None, 'under_sampler': None}, CV: 5\n",
      "Best parameters: {'classifier__depth': 4, 'classifier__iterations': 200, 'classifier__l2_leaf_reg': 2, 'classifier__learning_rate': 0.3, 'classifier__scale_pos_weight': 13, 'classifier__subsample': 0.8}\n",
      "Best cross-validation score: 0.30288485668870113\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.88      0.92      3624\n",
      "           1       0.21      0.52      0.30       231\n",
      "\n",
      "    accuracy                           0.85      3855\n",
      "   macro avg       0.59      0.70      0.61      3855\n",
      "weighted avg       0.92      0.85      0.88      3855\n",
      "\n",
      "      0    1\n",
      "0  3177  447\n",
      "1   112  119\n",
      "SMOTE config: {'smote': None, 'under_sampler': RandomUnderSampler(random_state=42, sampling_strategy=0.6)}, CV: 3\n",
      "Best parameters: {'classifier__depth': 6, 'classifier__iterations': 300, 'classifier__l2_leaf_reg': 2, 'classifier__learning_rate': 0.3, 'classifier__scale_pos_weight': 8, 'classifier__subsample': 0.8}\n",
      "Best cross-validation score: 0.257470671903749\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.68      0.81      3624\n",
      "           1       0.14      0.84      0.25       231\n",
      "\n",
      "    accuracy                           0.69      3855\n",
      "   macro avg       0.56      0.76      0.53      3855\n",
      "weighted avg       0.93      0.69      0.77      3855\n",
      "\n",
      "      0     1\n",
      "0  2475  1149\n",
      "1    37   194\n",
      "SMOTE config: {'smote': None, 'under_sampler': RandomUnderSampler(random_state=42, sampling_strategy=0.6)}, CV: 4\n",
      "Best parameters: {'classifier__depth': 8, 'classifier__iterations': 300, 'classifier__l2_leaf_reg': 2, 'classifier__learning_rate': 0.3, 'classifier__scale_pos_weight': 8, 'classifier__subsample': 0.8}\n",
      "Best cross-validation score: 0.25534423319472593\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.69      0.81      3624\n",
      "           1       0.14      0.81      0.24       231\n",
      "\n",
      "    accuracy                           0.69      3855\n",
      "   macro avg       0.56      0.75      0.52      3855\n",
      "weighted avg       0.93      0.69      0.77      3855\n",
      "\n",
      "      0     1\n",
      "0  2488  1136\n",
      "1    44   187\n",
      "SMOTE config: {'smote': None, 'under_sampler': RandomUnderSampler(random_state=42, sampling_strategy=0.6)}, CV: 5\n",
      "Best parameters: {'classifier__depth': 8, 'classifier__iterations': 300, 'classifier__l2_leaf_reg': 1, 'classifier__learning_rate': 0.4, 'classifier__scale_pos_weight': 8, 'classifier__subsample': 0.8}\n",
      "Best cross-validation score: 0.26199700833616296\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.69      0.81      3624\n",
      "           1       0.14      0.82      0.24       231\n",
      "\n",
      "    accuracy                           0.70      3855\n",
      "   macro avg       0.56      0.75      0.53      3855\n",
      "weighted avg       0.93      0.70      0.78      3855\n",
      "\n",
      "      0     1\n",
      "0  2496  1128\n",
      "1    42   189\n",
      "SMOTE config: {'smote': None, 'under_sampler': RandomUnderSampler(random_state=42, sampling_strategy=0.5)}, CV: 3\n",
      "Best parameters: {'classifier__depth': 8, 'classifier__iterations': 300, 'classifier__l2_leaf_reg': 2, 'classifier__learning_rate': 0.4, 'classifier__scale_pos_weight': 8, 'classifier__subsample': 0.8}\n",
      "Best cross-validation score: 0.27340989127695936\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.72      0.83      3624\n",
      "           1       0.15      0.79      0.26       231\n",
      "\n",
      "    accuracy                           0.73      3855\n",
      "   macro avg       0.57      0.76      0.55      3855\n",
      "weighted avg       0.93      0.73      0.80      3855\n",
      "\n",
      "      0    1\n",
      "0  2625  999\n",
      "1    48  183\n",
      "SMOTE config: {'smote': None, 'under_sampler': RandomUnderSampler(random_state=42, sampling_strategy=0.5)}, CV: 4\n",
      "Best parameters: {'classifier__depth': 8, 'classifier__iterations': 300, 'classifier__l2_leaf_reg': 2, 'classifier__learning_rate': 0.3, 'classifier__scale_pos_weight': 8, 'classifier__subsample': 0.8}\n",
      "Best cross-validation score: 0.263305946151692\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.71      0.83      3624\n",
      "           1       0.15      0.78      0.25       231\n",
      "\n",
      "    accuracy                           0.72      3855\n",
      "   macro avg       0.57      0.75      0.54      3855\n",
      "weighted avg       0.93      0.72      0.79      3855\n",
      "\n",
      "      0     1\n",
      "0  2590  1034\n",
      "1    50   181\n",
      "SMOTE config: {'smote': None, 'under_sampler': RandomUnderSampler(random_state=42, sampling_strategy=0.5)}, CV: 5\n",
      "Best parameters: {'classifier__depth': 8, 'classifier__iterations': 300, 'classifier__l2_leaf_reg': 2, 'classifier__learning_rate': 0.3, 'classifier__scale_pos_weight': 8, 'classifier__subsample': 0.8}\n",
      "Best cross-validation score: 0.27701358463993997\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.71      0.83      3624\n",
      "           1       0.15      0.78      0.25       231\n",
      "\n",
      "    accuracy                           0.72      3855\n",
      "   macro avg       0.57      0.75      0.54      3855\n",
      "weighted avg       0.93      0.72      0.79      3855\n",
      "\n",
      "      0     1\n",
      "0  2590  1034\n",
      "1    50   181\n",
      "SMOTE config: {'smote': None, 'under_sampler': RandomUnderSampler(random_state=42, sampling_strategy=0.4)}, CV: 3\n",
      "Best parameters: {'classifier__depth': 8, 'classifier__iterations': 300, 'classifier__l2_leaf_reg': 2, 'classifier__learning_rate': 0.3, 'classifier__scale_pos_weight': 8, 'classifier__subsample': 0.8}\n",
      "Best cross-validation score: 0.27187269111537876\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.74      0.84      3624\n",
      "           1       0.15      0.70      0.24       231\n",
      "\n",
      "    accuracy                           0.74      3855\n",
      "   macro avg       0.56      0.72      0.54      3855\n",
      "weighted avg       0.93      0.74      0.81      3855\n",
      "\n",
      "      0    1\n",
      "0  2694  930\n",
      "1    70  161\n",
      "SMOTE config: {'smote': None, 'under_sampler': RandomUnderSampler(random_state=42, sampling_strategy=0.4)}, CV: 4\n",
      "Best parameters: {'classifier__depth': 8, 'classifier__iterations': 300, 'classifier__l2_leaf_reg': 2, 'classifier__learning_rate': 0.3, 'classifier__scale_pos_weight': 8, 'classifier__subsample': 0.8}\n",
      "Best cross-validation score: 0.27440549813669224\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.74      0.84      3624\n",
      "           1       0.15      0.70      0.24       231\n",
      "\n",
      "    accuracy                           0.74      3855\n",
      "   macro avg       0.56      0.72      0.54      3855\n",
      "weighted avg       0.93      0.74      0.81      3855\n",
      "\n",
      "      0    1\n",
      "0  2694  930\n",
      "1    70  161\n",
      "SMOTE config: {'smote': None, 'under_sampler': RandomUnderSampler(random_state=42, sampling_strategy=0.4)}, CV: 5\n",
      "Best parameters: {'classifier__depth': 8, 'classifier__iterations': 300, 'classifier__l2_leaf_reg': 2, 'classifier__learning_rate': 0.3, 'classifier__scale_pos_weight': 8, 'classifier__subsample': 0.8}\n",
      "Best cross-validation score: 0.28829923824663695\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.74      0.84      3624\n",
      "           1       0.15      0.70      0.24       231\n",
      "\n",
      "    accuracy                           0.74      3855\n",
      "   macro avg       0.56      0.72      0.54      3855\n",
      "weighted avg       0.93      0.74      0.81      3855\n",
      "\n",
      "      0    1\n",
      "0  2694  930\n",
      "1    70  161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE config: {'smote': None, 'under_sampler': RandomUnderSampler(random_state=42, sampling_strategy=0.3)}, CV: 3\n",
      "Best parameters: {'classifier__depth': 8, 'classifier__iterations': 300, 'classifier__l2_leaf_reg': 2, 'classifier__learning_rate': 0.3, 'classifier__scale_pos_weight': 8, 'classifier__subsample': 0.8}\n",
      "Best cross-validation score: 0.2886256941884005\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.81      0.88      3624\n",
      "           1       0.18      0.67      0.29       231\n",
      "\n",
      "    accuracy                           0.80      3855\n",
      "   macro avg       0.58      0.74      0.59      3855\n",
      "weighted avg       0.93      0.80      0.85      3855\n",
      "\n",
      "      0    1\n",
      "0  2935  689\n",
      "1    76  155\n",
      "SMOTE config: {'smote': None, 'under_sampler': RandomUnderSampler(random_state=42, sampling_strategy=0.3)}, CV: 4\n",
      "Best parameters: {'classifier__depth': 6, 'classifier__iterations': 300, 'classifier__l2_leaf_reg': 2, 'classifier__learning_rate': 0.4, 'classifier__scale_pos_weight': 10, 'classifier__subsample': 0.8}\n",
      "Best cross-validation score: 0.28764691249405916\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.79      0.87      3624\n",
      "           1       0.16      0.61      0.25       231\n",
      "\n",
      "    accuracy                           0.78      3855\n",
      "   macro avg       0.56      0.70      0.56      3855\n",
      "weighted avg       0.92      0.78      0.83      3855\n",
      "\n",
      "      0    1\n",
      "0  2864  760\n",
      "1    89  142\n",
      "SMOTE config: {'smote': None, 'under_sampler': RandomUnderSampler(random_state=42, sampling_strategy=0.3)}, CV: 5\n",
      "Best parameters: {'classifier__depth': 8, 'classifier__iterations': 300, 'classifier__l2_leaf_reg': 1, 'classifier__learning_rate': 0.3, 'classifier__scale_pos_weight': 8, 'classifier__subsample': 0.8}\n",
      "Best cross-validation score: 0.29622678420964654\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.81      0.88      3624\n",
      "           1       0.18      0.65      0.28       231\n",
      "\n",
      "    accuracy                           0.80      3855\n",
      "   macro avg       0.58      0.73      0.58      3855\n",
      "weighted avg       0.93      0.80      0.85      3855\n",
      "\n",
      "      0    1\n",
      "0  2930  694\n",
      "1    81  150\n",
      "SMOTE config: {'smote': SMOTE(random_state=42, sampling_strategy=1.0), 'under_sampler': RandomUnderSampler(random_state=42, sampling_strategy=0.8)}, CV: 3\n",
      "Best parameters: {'classifier__depth': 6, 'classifier__iterations': 300, 'classifier__l2_leaf_reg': 2, 'classifier__learning_rate': 0.4, 'classifier__scale_pos_weight': 8, 'classifier__subsample': 0.8}\n",
      "Best cross-validation score: 0.24000979395197622\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.64      0.77      3624\n",
      "           1       0.13      0.87      0.23       231\n",
      "\n",
      "    accuracy                           0.65      3855\n",
      "   macro avg       0.56      0.75      0.50      3855\n",
      "weighted avg       0.94      0.65      0.74      3855\n",
      "\n",
      "      0     1\n",
      "0  2307  1317\n",
      "1    30   201\n",
      "SMOTE config: {'smote': SMOTE(random_state=42, sampling_strategy=1.0), 'under_sampler': RandomUnderSampler(random_state=42, sampling_strategy=0.8)}, CV: 4\n",
      "Best parameters: {'classifier__depth': 6, 'classifier__iterations': 200, 'classifier__l2_leaf_reg': 2, 'classifier__learning_rate': 0.4, 'classifier__scale_pos_weight': 8, 'classifier__subsample': 0.8}\n",
      "Best cross-validation score: 0.24235830033686268\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.62      0.77      3624\n",
      "           1       0.13      0.90      0.23       231\n",
      "\n",
      "    accuracy                           0.64      3855\n",
      "   macro avg       0.56      0.76      0.50      3855\n",
      "weighted avg       0.94      0.64      0.73      3855\n",
      "\n",
      "      0     1\n",
      "0  2263  1361\n",
      "1    24   207\n",
      "SMOTE config: {'smote': SMOTE(random_state=42, sampling_strategy=1.0), 'under_sampler': RandomUnderSampler(random_state=42, sampling_strategy=0.8)}, CV: 5\n",
      "Best parameters: {'classifier__depth': 6, 'classifier__iterations': 300, 'classifier__l2_leaf_reg': 1, 'classifier__learning_rate': 0.4, 'classifier__scale_pos_weight': 8, 'classifier__subsample': 0.8}\n",
      "Best cross-validation score: 0.24396622822384034\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.66      0.79      3624\n",
      "           1       0.14      0.85      0.24       231\n",
      "\n",
      "    accuracy                           0.68      3855\n",
      "   macro avg       0.56      0.76      0.52      3855\n",
      "weighted avg       0.93      0.68      0.76      3855\n",
      "\n",
      "      0     1\n",
      "0  2409  1215\n",
      "1    35   196\n",
      "\n",
      "Best overall result:\n",
      "SMOTE config: {'smote': None, 'under_sampler': None}, CV: 5\n",
      "Best parameters: {'classifier__depth': 4, 'classifier__iterations': 200, 'classifier__l2_leaf_reg': 2, 'classifier__learning_rate': 0.3, 'classifier__scale_pos_weight': 13, 'classifier__subsample': 0.8}\n",
      "Best cross-validation score: 0.30288485668870113\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.92</td>\n",
       "      <td>3624.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.30</td>\n",
       "      <td>231.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.59</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.61</td>\n",
       "      <td>3855.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.92</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.88</td>\n",
       "      <td>3855.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision  recall  f1-score  support\n",
       "0                  0.97    0.88      0.92  3624.00\n",
       "1                  0.21    0.52      0.30   231.00\n",
       "accuracy           0.85    0.85      0.85     0.85\n",
       "macro avg          0.59    0.70      0.61  3855.00\n",
       "weighted avg       0.92    0.85      0.88  3855.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0    1\n",
      "0  3177  447\n",
      "1   112  119\n",
      "\n",
      "Worst overall result:\n",
      "SMOTE config: {'smote': SMOTE(random_state=42, sampling_strategy=1.0), 'under_sampler': RandomUnderSampler(random_state=42, sampling_strategy=0.8)}, CV: 3\n",
      "Worst parameters: {'classifier__depth': 6, 'classifier__iterations': 300, 'classifier__l2_leaf_reg': 2, 'classifier__learning_rate': 0.4, 'classifier__scale_pos_weight': 8, 'classifier__subsample': 0.8}\n",
      "Worst cross-validation score: 0.24000979395197622\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.77</td>\n",
       "      <td>3624.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.13</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.23</td>\n",
       "      <td>231.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.65</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.56</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>3855.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.74</td>\n",
       "      <td>3855.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision  recall  f1-score  support\n",
       "0                  0.99    0.64      0.77  3624.00\n",
       "1                  0.13    0.87      0.23   231.00\n",
       "accuracy           0.65    0.65      0.65     0.65\n",
       "macro avg          0.56    0.75      0.50  3855.00\n",
       "weighted avg       0.94    0.65      0.74  3855.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0     1\n",
      "0  2307  1317\n",
      "1    30   201\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "data = pd.read_csv('fraud_vihecles.csv')\n",
    "\n",
    "# Set X and y\n",
    "X = data.drop(columns=['FraudFound_P'])\n",
    "y = data['FraudFound_P']\n",
    "\n",
    "# Split the data with stratification on the target column\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, stratify=y, random_state=42)\n",
    "\n",
    "# List of columns to drop\n",
    "columns_to_drop = ['PolicyNumber']\n",
    "\n",
    "# Define the preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('drop_columns', 'drop', columns_to_drop),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), X_train.columns.difference(columns_to_drop))\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'classifier__iterations': [200, 300],\n",
    "    'classifier__depth': [4, 6, 8],\n",
    "    'classifier__learning_rate': [0.3, 0.4],\n",
    "    'classifier__l2_leaf_reg': [1, 2],\n",
    "    'classifier__subsample': [0.8],\n",
    "    'classifier__scale_pos_weight': [8, 10, 13]\n",
    "}\n",
    "\n",
    "# SMOTE and under-sampling configurations based on the requirements\n",
    "smote_configs = [\n",
    "    # Keep the original class proportion\n",
    "    {'smote': None, 'under_sampler': None},\n",
    "    # Keep the same fraud, downsample non-fraudulent rows by different percentages\n",
    "    {'smote': None, 'under_sampler': RandomUnderSampler(sampling_strategy=0.6, random_state=42)},\n",
    "    {'smote': None, 'under_sampler': RandomUnderSampler(sampling_strategy=0.5, random_state=42)},\n",
    "    {'smote': None, 'under_sampler': RandomUnderSampler(sampling_strategy=0.4, random_state=42)},\n",
    "    {'smote': None, 'under_sampler': RandomUnderSampler(sampling_strategy=0.3, random_state=42)},\n",
    "    # Increase fraud by 100%, downsample non-fraudulent rows by 80%\n",
    "    {'smote': SMOTE(sampling_strategy=1.0, random_state=42), 'under_sampler': RandomUnderSampler(sampling_strategy=0.8, random_state=42)}\n",
    "]\n",
    "\n",
    "# Cross-validation strategies\n",
    "cv_strategies = [3, 4, 5]\n",
    "\n",
    "best_results = []\n",
    "\n",
    "# Define the F-beta scorer with beta=1.0 (F1 score)\n",
    "fbeta_scorer = make_scorer(fbeta_score, beta=1.0, pos_label=1)\n",
    "\n",
    "# Loop through SMOTE configurations and CV strategies\n",
    "for smote_config in smote_configs:\n",
    "    for cv in cv_strategies:\n",
    "        pipeline = ImbPipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('under_sampler', smote_config['under_sampler']),\n",
    "            ('smote', smote_config['smote']),\n",
    "            ('classifier', CatBoostClassifier(random_state=42, eval_metric='Logloss', verbose=0))\n",
    "        ])\n",
    "        \n",
    "        grid_search = GridSearchCV(pipeline, param_grid, cv=cv, scoring=fbeta_scorer, n_jobs=-1)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        \n",
    "        best_params = grid_search.best_params_\n",
    "        best_score = grid_search.best_score_\n",
    "        \n",
    "        y_pred = grid_search.predict(X_test)\n",
    "        report = classification_report(y_test, y_pred, output_dict=True)\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        \n",
    "        best_results.append({\n",
    "            'smote_config': smote_config,\n",
    "            'cv': cv,\n",
    "            'best_params': best_params,\n",
    "            'best_score': best_score,\n",
    "            'classification_report': report,\n",
    "            'confusion_matrix': cm\n",
    "        })\n",
    "        \n",
    "        print(f\"SMOTE config: {smote_config}, CV: {cv}\")\n",
    "        print(f\"Best parameters: {best_params}\")\n",
    "        print(f\"Best cross-validation score: {best_score}\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        print(pd.DataFrame(cm, index=grid_search.classes_, columns=grid_search.classes_))\n",
    "\n",
    "# Find the best overall result\n",
    "best_result = max(best_results, key=lambda x: x['best_score'])\n",
    "\n",
    "print(\"\\nBest overall result:\")\n",
    "print(f\"SMOTE config: {best_result['smote_config']}, CV: {best_result['cv']}\")\n",
    "print(f\"Best parameters: {best_result['best_params']}\")\n",
    "print(f\"Best cross-validation score: {best_result['best_score']}\")\n",
    "display(pd.DataFrame(best_result['classification_report']).transpose().round(2))\n",
    "print(pd.DataFrame(best_result['confusion_matrix'], index=grid_search.classes_, columns=grid_search.classes_))\n",
    "\n",
    "# Find the worst overall result\n",
    "worst_result = min(best_results, key=lambda x: x['best_score'])\n",
    "\n",
    "print(\"\\nWorst overall result:\")\n",
    "print(f\"SMOTE config: {worst_result['smote_config']}, CV: {worst_result['cv']}\")\n",
    "print(f\"Worst parameters: {worst_result['best_params']}\")\n",
    "print(f\"Worst cross-validation score: {worst_result['best_score']}\")\n",
    "display(pd.DataFrame(worst_result['classification_report']).transpose().round(2))\n",
    "print(pd.DataFrame(worst_result['confusion_matrix'], index=grid_search.classes_, columns=grid_search.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4de42a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bbae610c",
   "metadata": {},
   "source": [
    "## 8. Trying a voter on 4 models (apart from Decision Trees) out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "f03689e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined model results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.87      0.92      3624\n",
      "           1       0.20      0.51      0.29       231\n",
      "\n",
      "    accuracy                           0.85      3855\n",
      "   macro avg       0.59      0.69      0.60      3855\n",
      "weighted avg       0.92      0.85      0.88      3855\n",
      "\n",
      "      0    1\n",
      "0  3166  458\n",
      "1   113  118\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "data = pd.read_csv('fraud_vihecles.csv')\n",
    "\n",
    "# Set X and y\n",
    "X = data.drop(columns=['FraudFound_P'])\n",
    "y = data['FraudFound_P']\n",
    "\n",
    "# Split the data with stratification on the target column\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, stratify=y, random_state=42)\n",
    "\n",
    "# List of columns to drop\n",
    "columns_to_drop = ['PolicyNumber']\n",
    "\n",
    "# Define the preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('drop_columns', 'drop', columns_to_drop),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), X_train.columns.difference(columns_to_drop))\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Define the hyperparameters for Logistic Regression, Random Forest, XGBoost and CatBoost\n",
    "\n",
    "lr_params = {\n",
    "    'C': 1,\n",
    "    'penalty': 'l1',\n",
    "    'solver': 'liblinear',\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "rfc_params = {\n",
    "    'n_estimators': 300,\n",
    "    'max_depth': 20,\n",
    "    'min_samples_leaf': 1,\n",
    "    'min_samples_split': 5,\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "xgb_params = {\n",
    "    'n_estimators': 200,\n",
    "    'learning_rate': 0.2,\n",
    "    'max_depth': 4,\n",
    "    'scale_pos_weight': 13,\n",
    "    'subsample': 0.8,\n",
    "    'min_child_weight': 5,\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "catboost_params = {\n",
    "    'iterations': 200,\n",
    "    'learning_rate': 0.3,\n",
    "    'depth': 4,\n",
    "    'random_state': 42,\n",
    "    'verbose': False,\n",
    "    'l2_leaf_reg': 2,\n",
    "    'scale_pos_weight': 13,\n",
    "    'subsample': 0.8\n",
    "}\n",
    "\n",
    "\n",
    "# Instantiate the models\n",
    "lr_model = LogisticRegression(**lr_params)\n",
    "rfc_model = RandomForestClassifier(**rfc_params)\n",
    "xgb_model = XGBClassifier(**xgb_params)\n",
    "catboost_model = CatBoostClassifier(**catboost_params)\n",
    "\n",
    "# Define the SMOTE and under-sampling configurations for each model\n",
    "smote_config_lr = {\n",
    "    'smote': None, \n",
    "    'under_sampler': RandomUnderSampler(random_state=42, sampling_strategy=0.5)\n",
    "}\n",
    "\n",
    "smote_config_rfc = {\n",
    "    'smote': None, \n",
    "    'under_sampler': RandomUnderSampler(random_state=42, sampling_strategy=0.4)\n",
    "}\n",
    "\n",
    "smote_config_xgb = {\n",
    "    'smote': None, \n",
    "    'under_sampler': None\n",
    "}\n",
    "\n",
    "smote_config_catboost = {\n",
    "    'smote': None, \n",
    "    'under_sampler': None\n",
    "}\n",
    "\n",
    "# Define the pipelines for each model\n",
    "pipeline_lr = ImbPipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('under_sampler', smote_config_lr['under_sampler']),\n",
    "    ('smote', smote_config_lr['smote']),\n",
    "    ('classifier', lr_model)\n",
    "])\n",
    "\n",
    "pipeline_rfc = ImbPipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('under_sampler', smote_config_rfc['under_sampler']),\n",
    "    ('smote', smote_config_rfc['smote']),\n",
    "    ('classifier', rfc_model)\n",
    "])\n",
    "\n",
    "pipeline_xgb = ImbPipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('under_sampler', smote_config_xgb['under_sampler']),\n",
    "    ('smote', smote_config_xgb['smote']),\n",
    "    ('classifier', xgb_model)\n",
    "])\n",
    "\n",
    "pipeline_catboost = ImbPipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('under_sampler', smote_config_catboost['under_sampler']),\n",
    "    ('smote', smote_config_catboost['smote']),\n",
    "    ('classifier', catboost_model)\n",
    "])\n",
    "\n",
    "# Fit the pipelines to the training data\n",
    "pipeline_lr.fit(X_train, y_train)\n",
    "pipeline_rfc.fit(X_train, y_train)\n",
    "pipeline_xgb.fit(X_train, y_train)\n",
    "pipeline_catboost.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred_lr = pipeline_lr.predict(X_test)\n",
    "y_pred_rfc = pipeline_rfc.predict(X_test)\n",
    "y_pred_xgb = pipeline_xgb.predict(X_test)\n",
    "y_pred_catboost = pipeline_catboost.predict(X_test)\n",
    "\n",
    "# Combine the predictions using VotingClassifier\n",
    "voter = VotingClassifier(estimators=[\n",
    "     ('lr', pipeline_lr),\n",
    "    ('rfc', pipeline_rfc),\n",
    "    ('xgb', pipeline_xgb),\n",
    "    ('catboost', pipeline_catboost)\n",
    "], voting='soft')\n",
    "\n",
    "voter.fit(X_train, y_train)\n",
    "y_pred_voter = voter.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "report = classification_report(y_test, y_pred_voter, output_dict=True)\n",
    "cm = confusion_matrix(y_test, y_pred_voter)\n",
    "\n",
    "results = {\n",
    "    'classification_report': report,\n",
    "    'confusion_matrix': cm\n",
    "}\n",
    "\n",
    "# Print the results\n",
    "print(f\"Combined model results:\")\n",
    "print(classification_report(y_test, y_pred_voter))\n",
    "print(pd.DataFrame(cm, index=voter.classes_, columns=voter.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ea4a96",
   "metadata": {},
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a0288b",
   "metadata": {},
   "source": [
    "1. None of the models showed decent results to 'be used in production'\n",
    "2. XGBoost happened to show the best results\n",
    "3. Voting didn't really improve the prediciton power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e12d909",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
