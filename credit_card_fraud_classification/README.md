# ğŸ’³ Credit Card Fraud Detection

A classification project focused on detecting fraudulent credit card transactions using advanced machine learning models including XGBoost, LightGBM, CatBoost, and an ensemble Voting Classifier. This project handles real-world challenges such as highly imbalanced data and high-cardinality categorical features.

---

## ğŸ“ Project Structure

```
ğŸ“‚ Credit_Card_Fraud_Detection/
â”œâ”€â”€ Credit Card Fraud Detection Project EDA.ipynb       # EDA and insights
â”œâ”€â”€ 1. Credit Card Fraud Detection Modeling XGBoost.ipynb
â”œâ”€â”€ 2. Credit Card Fraud Detection Modeling LightGBM.ipynb
â”œâ”€â”€ 3. Credit Card Fraud Detection Modeling CatBoost.ipynb
â”œâ”€â”€ 4. Credit Card Fraud Detection Modeling with Voting.ipynb
â”œâ”€â”€ DS Project - Credit Card Fraud Detection.pptx       # Final presentation
â””â”€â”€ README.md                                           # This file
```

---

## ğŸ” Project Overview

Credit card fraud costs billions annually. Common fraud tactics include:

- Phishing attacks via email/SMS
- Breaches of retailer databases
- Disputing legitimate charges (friendly fraud)

Visa and Mastercard apply **strict fraud thresholds**, imposing **fines** if exceeded. For example, Visa fines start at **$10,000/month** once fraud exceeds 0.65â€“1.80% of total monthly volume.

This project tackles fraud detection using supervised learning on a real-world style dataset.

---

## ğŸ§¾ Dataset Info

- ğŸ“‚ Source: Kaggle (simulated dataset)
- ğŸ“† Period: 2020â€“2022
- ğŸ§® Size: 1.3M rows (train), 0.5M (test), 23 columns
- ğŸ¯ Target: `is_fraud` (1 = fraud, 0 = not fraud)
- âš ï¸ Imbalance: Only **0.58%** of transactions are fraud

Columns include transaction details, customer demographics, merchant info, etc.

---

## ğŸ“Š Key EDA Highlights

- Fraud is more likely in transactions between **$500â€“$1000**
- Night-time (22:00â€“03:00) has the highest fraud activity
- **Shopping_net** and **Shopping_pos** are top fraud categories
- Top 3 categories account for **58% of fraud** but only **23% of all transactions**
- City population, gender, and job features had low predictive power
- Feature engineering created `age`, `hour`, `day_of_week`, and `month`

---

## âš™ï¸ Preprocessing & Feature Engineering

- Dropped columns: `trans_date_trans_time`, `cc_num`, `first`, `last`, `street`, `zip`, `dob`, `trans_num`, `lat`, `long`, `merch_lat`, `merch_long`
- One-hot encoding used for all categorical features â†’ expanded to **2151 columns**
- Data saved as Parquet for memory efficiency
- Downsampling performed to address class imbalance

---

## ğŸ¤– Models Used

- XGBoost
- LightGBM
- CatBoost
- VotingClassifier (ensemble)

### Strategy

- Custom hyperparameter tuning for each model
- Metrics focused on **precision and recall**
- **50% downsampling** yielded best results
- `shap` used for interpretability and feature importance
- Manual tuning due to memory limits

---

## ğŸ“ˆ Final Results

- All models performed similarly
- **LightGBM** was significantly faster and most balanced
- Top features included: `category`, `amount`, `hour`, `merchant`, and engineered features

---

## ğŸš§ Challenges

- **Memory issues** due to large one-hot encoded dataset
- LightGBM required sanitizing column names with special characters
- Kernel restarts needed frequently during tuning

---

## âœ… Conclusion

- Fraud detection on highly imbalanced data is complex but solvable with careful preprocessing and model tuning
- **LightGBM** is the preferred model for this dataset
- Ensemble models did not outperform single best models
- Precision/recall trade-off is critical for real-world fraud prevention

---

## ğŸ‘¤ Author

**Aleksander Tanskii**  

---

If youâ€™re working on a fraud detection system, feel free to explore, fork, or contribute. Letâ€™s catch those fraudsters! ğŸ•µï¸â€â™‚ï¸ğŸ’¸
